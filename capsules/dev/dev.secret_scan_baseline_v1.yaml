id: dev.secret_scan_baseline_v1
version: 1.0.0
domain: dev
title: Secret Scan Baseline (No Keys, No High-Entropy Blobs)
statement: 'Scan source tree for obvious secrets and high-entropy blobs. Skip vendor
  and binary paths.

  Fail on suspected credentials or suspicious entropy across text files.'
witnesses:
- name: no_high_entropy_or_keys
  language: python
  entrypoint: python3
  args: []
  env:
    REPO_PATH: .
    INCLUDE_GLOBS_JSON: '["**/*.py","**/*.js","**/*.ts","**/*.go","**/*.rs","**/*.java","**/*.sh","**/*.yaml","**/*.yml","**/*.toml","**/*.ini","**/*.cfg","**/*.conf"]'
    EXCLUDE_GLOBS_JSON: '["**/.env*","**/out/**","**/dist/**","**/build/**","**/node_modules/**","**/.git/**","**/__pycache__/**","**/*.json","**/*.ndjson","**/*.ttl","**/*.md"]'
    SKIP_DIRS_JSON: '[".git","node_modules","venv",".venv",".cache","dist","build","__pycache__"]'
    MAX_FILES: '2000'
    MAX_FILE_BYTES: '200000'
    ENTROPY_THRESHOLD: '5.2'
    TOKEN_MINLEN: '20'
    KEY_REGEXES_JSON: "[\n  \"(?i)aws[_-]?access[_-]?key[_-]?id\",\n  \"(?i)aws[_-]?secret[_-]?access[_-]?key\"\
      ,\n  \"(?i)gh[_-]?token|github[_-]?token\",\n  \"(?i)slack[_-]?(token|webhook)\"\
      ,\n  \"(?i)api[_-]?key|secret[_-]?key|private[_-]?key\",\n  \"-----BEGIN\\\\\
      s+PRIVATE\\\\s+KEY-----\"\n]\n"
  timeout_ms: 8000
  memory_mb: 256
  net: false
  fs_mode: ro
  code: "import os, sys, json, math, fnmatch, re\n\ndef env_json(name, default):\n\
    \    try: return json.loads(os.environ.get(name, json.dumps(default)))\n    except\
    \ Exception: return default\n\ndef env_int(name, default):\n    try: return int(os.environ.get(name,\
    \ str(default)))\n    except Exception: return default\n\ndef env_float(name,\
    \ default):\n    try: return float(os.environ.get(name, str(default)))\n    except\
    \ Exception: return default\n\ndef shannon_entropy(s):\n    if not s: return 0.0\n\
    \    freq = {}\n    for ch in s: freq[ch] = freq.get(ch, 0) + 1\n    H = 0.0\n\
    \    ln = len(s)\n    for c in freq.values():\n        p = c / ln\n        H -=\
    \ p * math.log2(p)\n    return H\n\ndef looks_binary(b):\n    return (b.count(b\"\
    \\x00\") > 0) or any(c < 9 for c in b[:64])\n\ndef read_limited(path, max_bytes):\n\
    \    with open(path, \"rb\") as f: return f.read(max_bytes)\n\ndef match_any_glob(path,\
    \ globs):\n    return any(fnmatch.fnmatch(path, g) for g in globs)\n\ndef main():\n\
    \    root = os.environ.get(\"REPO_PATH\", \".\")\n    include_globs = env_json(\"\
    INCLUDE_GLOBS_JSON\", [])\n    exclude_globs = env_json(\"EXCLUDE_GLOBS_JSON\"\
    , [])\n    skip_dirs = set(env_json(\"SKIP_DIRS_JSON\", []))\n    max_files =\
    \ env_int(\"MAX_FILES\", 2000)\n    max_bytes = env_int(\"MAX_FILE_BYTES\", 200000)\n\
    \    thr = env_float(\"ENTROPY_THRESHOLD\", 5.2)\n    token_min = env_int(\"TOKEN_MINLEN\"\
    , 20)\n    key_res = [re.compile(p) for p in env_json(\"KEY_REGEXES_JSON\", [])]\n\
    \    token_re = re.compile(rf\"[A-Za-z0-9+/=_-]{{{token_min},}}\")\n\n    findings,\
    \ scanned = [], 0\n\n    for cur, dirs, files in os.walk(root):\n        dirs[:]\
    \ = [d for d in dirs if os.path.join(cur, d).split(os.sep)[-1] not in skip_dirs]\n\
    \        for name in files:\n            rel = os.path.relpath(os.path.join(cur,\
    \ name), root)\n            if exclude_globs and match_any_glob(rel, exclude_globs):\
    \ continue\n            if include_globs and not match_any_glob(rel, include_globs):\
    \ continue\n\n            scanned += 1\n            if scanned > max_files:\n\
    \                findings.append({\"limit\": \"max_files_reached\", \"scanned\"\
    : scanned})\n                break\n\n            try: data = read_limited(os.path.join(root,\
    \ rel), max_bytes)\n            except Exception: continue\n            if looks_binary(data):\
    \ continue\n\n            try: text = data.decode(\"utf-8\", \"ignore\")\n   \
    \         except Exception: continue\n\n            # Regex hits (keys/secrets\
    \ style)\n            regex_hits = []\n            for rx in key_res:\n      \
    \          if rx.search(text):\n                    regex_hits.append(rx.pattern)\n\
    \n            # Token-level entropy (not whole file): find long base64/hex-ish\
    \ substrings\n            token_hits = []\n            for tok in token_re.findall(text):\n\
    \                H = shannon_entropy(tok)\n                if H >= thr:\n    \
    \                token_hits.append({\"token_len\": len(tok), \"entropy\": round(H,\
    \ 3)})\n\n            if regex_hits or token_hits:\n                findings.append({\n\
    \                    \"file\": rel,\n                    \"regex_hits\": regex_hits,\n\
    \                    \"token_hits\": token_hits[:5]\n                })\n\n  \
    \      if scanned > max_files: break\n\n    ok = len([f for f in findings if \"\
    file\" in f]) == 0\n    out = {\n        \"ok\": ok,\n        \"findings\": findings[:50],\n\
    \        \"scanned_files\": scanned,\n        \"root\": root,\n        \"limits\"\
    : {\n            \"max_files\": max_files,\n            \"max_file_bytes\": max_bytes,\n\
    \            \"entropy_threshold\": thr,\n            \"token_minlen\": token_min\n\
    \        },\n        \"skipped_dirs\": sorted(skip_dirs),\n        \"include_globs\"\
    : include_globs,\n        \"exclude_globs\": exclude_globs\n    }\n    print(json.dumps(out,\
    \ indent=2))\n    sys.exit(0 if ok else 1)\n\nif __name__ == \"__main__\":\n \
    \   main()"
provenance:
  schema: provenance.v1
  author: John Macgregor
  org: Truth Capsules Demo
  license: MIT
  source_url: https://example.com/truth-capsules/dev
  created: '2025-11-10T20:25:00Z'
  updated: '2025-11-10T20:25:00Z'
  review:
    status: draft
    reviewers: []
    last_reviewed: null
  signing:
    method: ed25519
    key_id: null
    pubkey: null
    digest: 5e11b266206c16e506db61302e8ad24cd5f4d7554b05b9c7837bb27d58421149
    signature: null
applies_to:
- conversation
- code_assistant
- review
security:
  sensitivity: medium
  notes: ''
