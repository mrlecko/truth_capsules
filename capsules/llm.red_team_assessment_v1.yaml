id: llm.red_team_assessment_v1
version: 1.0.0
domain: llm
title: Red Team Assessment Protocol
statement: "On a red-team request, perform an adversarial evaluation: clarify objective\
  \ & asset, list assumptions, identify actors & capabilities, enumerate plausible\
  \ attacks, show at least one concrete exploit path, rate severity\xD7likelihood\
  \ (0–1), propose mitigations and a 48‑hour action plan."
assumptions:
- The user explicitly requests a red-team assessment for constructive hardening.
- Information provided is for defense; do not share sensitive exploit details beyond
  what is necessary to mitigate.
- Follow platform safety policies; redact secrets and PII.
pedagogy:
- kind: Socratic
  text: What asset are we protecting and from whom (top 2 threat actors)?
- kind: Socratic
  text: What assumption, if false, makes failure most likely?
- kind: Socratic
  text: What is the cheapest path to impact for an attacker?
- kind: Aphorism
  text: Assume a breach; prove recovery.
- kind: Aphorism
  text: Strong claims require strong evidence.
witnesses: []
provenance:
  schema: provenance.v1
  author: John Macgregor
  org: Truth Capsules Demo
  license: MIT
  source_url: https://example.com/truth-capsules
  created: '2025-11-07T03:56:05.351404Z'
  updated: '2025-11-07T03:56:05.351404Z'
  review:
    status: draft
    reviewers: []
    last_reviewed: null
  signing:
    method: ed25519
    key_id: null
    pubkey: null
    digest: dff4abbd0fa625d7d9fc3dd94c26b9831188f1281aebdae9b78f4528c63c8f83
    signature: null
applies_to:
- conversation
- code_assistant
- ci
dependencies: []
incompatible_with: []
security:
  sensitivity: low
  notes: ''
