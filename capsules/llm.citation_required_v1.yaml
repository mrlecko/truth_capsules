id: llm.citation_required_v1
version: 1.0.0
domain: llm
title: Citations required
statement: Answers must include at least one citation or abstain.
assumptions:
- Operating in a general context
pedagogy:
- kind: Socratic
  text: What evidence supports this claim?
- kind: Aphorism
  text: Cite or abstain.
witnesses:
  - name: citations_cover_claims
    language: python
    env:
      ANSWER_PATH: artifacts/examples/answer_with_citation.json
      COVERAGE_MIN: "0.6"         # ≥60% declarative sentences must be cited
      DIVERSITY_MAX: "0.7"         # ≤70% of refs may come from one domain
      ALLOWLIST: "doi.org,arxiv.org,acm.org,ieee.org,nature.com,sciencemag.org,gov,edu"
      DOC_CLASS: ""                # set to "opinion" to SKIP
    code: |-
      import os, re, json, sys, pathlib
      from urllib.parse import urlparse

      ap = pathlib.Path(os.getenv("ANSWER_PATH","")).resolve()
      if not ap.exists():
          print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"file-not-found","inputs":{"answer":str(ap)}}))
          sys.exit(1)

      # Opinion content can SKIP (policy-controlled)
      if os.getenv("DOC_CLASS","").lower() == "opinion":
          print(json.dumps({"witness":"citations_cover_claims","status":"SKIP","reason":"opinion-doc","inputs":{"answer":str(ap)}}))
          sys.exit(0)

      data = json.loads(ap.read_text(encoding="utf-8"))
      answer = (data.get("answer") or "").strip()
      refs = data.get("references") or []

      # Very light sentence segmentation (declarative-ish)
      sentences = [s.strip() for s in re.split(r'(?<=[.!?])\s+', answer) if s.strip()]
      # Extract [n] citations
      cite_pat = re.compile(r'\[(\d+)\]')
      cited_flags = [bool(cite_pat.search(s)) for s in sentences]
      total = len(sentences)
      cited = sum(cited_flags)

      # Build ref index and domains
      ref_by_id = {int(r.get("id")): r for r in refs if isinstance(r.get("id"), int) and r.get("url")}
      domains = []
      for r in refs:
          try:
              host = urlparse(r.get("url","")).netloc.lower()
              if host: domains.append(host)
          except Exception:
              pass

      # Policies
      COVERAGE_MIN = float(os.getenv("COVERAGE_MIN","0.6"))
      DIVERSITY_MAX = float(os.getenv("DIVERSITY_MAX","0.7"))
      ALLOWLIST = [d.strip().lower() for d in os.getenv("ALLOWLIST","").split(",") if d.strip()]

      def domain_class(host):
          if host.endswith(".gov") or host.endswith(".edu") or host in ALLOWLIST or any(host.endswith(d) for d in ALLOWLIST):
              return "preferred"
          return "other"

      # Reference integrity checks
      # 1) No citations at all → FAIL (unless no declaratives → SKIP)
      if total == 0:
          print(json.dumps({"witness":"citations_cover_claims","status":"SKIP","reason":"no-declaratives","inputs":{"answer":str(ap)}}))
          sys.exit(0)

      found_cites = [int(n) for n in cite_pat.findall(answer)]
      if not found_cites:
          print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"no-citations","inputs":{"answer":str(ap)}}))
          sys.exit(1)

      # 2) Every [n] must exist in references
      missing_map = sorted({n for n in set(found_cites) if n not in ref_by_id})
      if missing_map:
          print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"missing-refs","missing_ids":missing_map,"inputs":{"answer":str(ap)}}))
          sys.exit(1)

      # 3) Sequential numbering starting at 1 (soft check)
      if ref_by_id and (min(ref_by_id) != 1 or max(ref_by_id) != len(ref_by_id)):
          # Not fatal, but record as warning in output payload
          numbering_warn = True
      else:
          numbering_warn = False

      # 4) Coverage threshold
      coverage = cited/total if total else 0.0
      if coverage < COVERAGE_MIN:
          print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"coverage-too-low","coverage":coverage,"min":COVERAGE_MIN,"inputs":{"answer":str(ap)}}))
          sys.exit(1)

      # 5) Diversity (prevent single-domain echo chamber)
      from collections import Counter
      dom_counts = Counter(domains)
      if dom_counts:
          top_dom, top_cnt = dom_counts.most_common(1)[0]
          if top_cnt/len(domains) > DIVERSITY_MAX:
              print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"source-too-concentrated","top_domain":top_dom,"share":top_cnt/len(domains),"max":DIVERSITY_MAX,"inputs":{"answer":str(ap)}}))
              sys.exit(1)

          # Disallow all-wikipedia (or single non-preferred domain) cases
          if len(dom_counts) == 1 and ("wikipedia.org" in dom_counts):
              print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"all-wikipedia","inputs":{"answer":str(ap)}}))
              sys.exit(1)

      # 6) Allowlist presence (at least one preferred or academic/governmental source)
      has_pref = any(domain_class(h)=="preferred" for h in domains)
      if not has_pref and refs:
          print(json.dumps({"witness":"citations_cover_claims","status":"FAIL","reason":"no-preferred-sources","inputs":{"answer":str(ap)}}))
          sys.exit(1)

      out = {
          "witness":"citations_cover_claims",
          "status":"PASS",
          "coverage": coverage,
          "sequential_numbering_warn": numbering_warn,
          "totals":{"sentences": total, "cited": cited, "refs": len(refs)},
          "inputs":{"answer": str(ap)}
      }
      print(json.dumps(out, indent=2))
      sys.exit(0)
provenance:
  schema: provenance.v1
  author: John Macgregor
  org: Truth Capsules Demo
  license: MIT
  source_url: https://example.com/truth-capsules
  created: '2025-11-07T03:53:50.511776Z'
  updated: '2025-11-07T03:56:05.351404Z'
  review:
    status: draft
    reviewers: []
    last_reviewed: null
  signing:
    method: ed25519
    key_id: null
    pubkey: null
    digest: 0a51607ced8bd646d4a3bcaf8fa3c8ef4c5519afe87615669c6ad389d725cb39
    signature: null
applies_to:
- conversation
- code_assistant
- ci
dependencies: []
incompatible_with: []
security:
  sensitivity: low
  notes: ''
