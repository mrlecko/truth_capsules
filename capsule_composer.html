<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Truth Capsule Prompt Composer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- THEME + LAYOUT -->
  <style>
    :root {
      --bg: #0f1115;
      /* page background */
      --panel: #161a20;
      /* cards / panels */
      --panel-alt: #1b2028;
      /* code blocks */
      --text: #e6eaf2;
      /* primary text */
      --muted: #a9b1c3;
      /* secondary text */
      --accent: #7aa2ff;
      /* interactive/links */
      --border: #232a36;
      /* borders */
      --chip: #212734;
      /* chips */
      --chip-border: #2c3443;
      --ok: #46d39a;
      --danger: #ff6b6b;
    }

    * {
      box-sizing: border-box
    }

    html,
    body {
      height: 100%
    }

    body {
      margin: 0;
      background: var(--bg);
      color: var(--text);
      font: 18px/1.5 ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Arial;
    }

    /* Global *webkit* scrollbars (applied to every scrollable element) */
    *::-webkit-scrollbar {
      width: 12px;
      height: 12px
    }

    *::-webkit-scrollbar-thumb {
      background: #2a3545;
      border-radius: 8px;
      border: 2px solid var(--bg)
    }

    *::-webkit-scrollbar-track {
      background: var(--bg)
    }

    /* header (sticky toolbar) */
    header {
      display: flex;
      gap: 12px;
      align-items: center;
      padding: 12px 16px;
      border-bottom: 1px solid var(--border);
      background: var(--panel);
      position: sticky;
      top: 0;
      z-index: 50
    }

    h1 {
      font-size: 16px;
      margin: 0
    }

    header .small {
      color: var(--muted)
    }

    /* split layout (Split.js) */
    main {
      position: relative;
      height: calc(100vh - 54px)
    }

    #split {
      display: flex;
      height: 100%
    }

    #left,
    #right {
      overflow: hidden
    }

    /* children manage their own overflow */
    #left {
      min-width: 260px;
      max-width: 40vw;
      display: flex;
      flex-direction: column
    }

    /* left top controls (search + profile) */
    #leftTop {
      padding: 12px;
      border-bottom: 1px solid var(--border)
    }

    /* left inner vertical split (bundles/capsules) */
    #leftSplit {
      flex: 1;
      display: flex;
      flex-direction: column;
      height: 100%;
      min-height: 0
    }

    .section-block {
      display: flex;
      flex-direction: column;
      overflow: hidden;
      padding: 12px;
      min-height: 0
    }

    .section-title {
      font-weight: 600;
      margin-bottom: 8px;
      flex-shrink: 0
    }

    .list {
      display: flex;
      flex-direction: column;
      gap: 6px;
      overflow-y: auto;
      overflow-x: hidden;
      flex: 1;
      min-height: 0
    }

    .item {
      background: var(--panel);
      border: 1px solid var(--border);
      border-radius: 10px;
      padding: 8px
    }

    .row {
      display: flex;
      gap: 10px;
      align-items: center;
      flex-wrap: wrap
    }

    .small {
      font-size: 16px;
      color: var(--muted)
    }

    .chip {
      background: var(--chip);
      border: 1px solid var(--chip-border);
      border-radius: 12px;
      padding: 4px 8px;
      display: inline-flex;
      align-items: center;
      gap: 6px
    }

    .chip:hover {
      border-color: var(--accent);
      box-shadow: 0 0 0 2px color-mix(in oklab, var(--accent), transparent 80%)
    }

    .drag {
      cursor: grab;
      user-select: none
    }

    .drag:active {
      cursor: grabbing
    }

    /* right column */
    section {
      display: flex;
      flex-direction: column;
      gap: 12px;
      padding: 12px
    }

    .card {
      background: var(--panel);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 12px
    }

    .btn {
      padding: 6px 10px;
      border: 1px solid var(--border);
      border-radius: 8px;
      background: #0e141e;
      color: var(--text);
      cursor: pointer
    }

    .btn:hover {
      border-color: var(--accent)
    }

    .btn.warn {
      background: color-mix(in oklab, var(--danger), #000 80%);
      color: #ffdcdc
    }

    .btn.small {
      font-size: 14px;
      padding: 4px 8px
    }

    select,
    input[type="text"] {
      background: #0e141e;
      border: 1px solid var(--border);
      color: var(--text);
      padding: 6px;
      border-radius: 8px;
      font-size:16px;
    }

    /* code / text areas */
    pre,
    textarea {
      width: 100%;
      min-height: 240px;
      white-space: pre-wrap;
      word-break: break-word;
      background: var(--panel-alt);
      border: 1px solid var(--border);
      color: #00ff68; /* var(--text); */
      border-radius: 10px;
      padding: 12px;
      font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;
      font-size: 15.5px;
      line-height: 1.5;
      tab-size: 2
    }

    /* badges */
    .badge {
      display: inline-block;
      padding: 2px 6px;
      border-radius: 10px;
      background: #20314a;
      color: #c2d1f3;
      font-size: 13px;
      border: 1px solid #1a2537
    }

    .badge.ok {
      background: color-mix(in oklab, var(--ok), #000 75%);
      color: #c6f6df;
      border-color: #1b3a30
    }

    .badge.err {
      background: color-mix(in oklab, var(--danger), #000 75%);
      color: #ffd6d6;
      border-color: #4a1b1b
    }

    /* horizontal (vertical-direction) gutter between Bundles & Capsules */
    .gutter.gutter-vertical {
      height: 8px;
      cursor: row-resize;
      background: linear-gradient(to bottom, transparent 0, transparent 3px, #ffffff33 3px, #ffffff33 5px, transparent 5px);
    }

    .gutter.gutter-vertical:hover {
      background: #ffffff44
    }

    /* vertical (left/right) gutter */
    .gutter {
      background: transparent;
      cursor: col-resize
    }

    .gutter:hover {
      background: rgba(122, 162, 255, .08)
    }

    /* modal */
    #modal,
    #llmModal {
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.5);
      display: none;
      align-items: center;
      justify-content: center;
      z-index: 100
    }

    #modal .modal-inner,
    #llmModal .modal-inner {
      background: var(--panel-alt);
      border: 1px solid var(--border);
      border-radius: 12px;
      max-width: 900px;
      width: 92%;
      max-height: 80vh;
      overflow: auto;
      padding: 12px
    }

    #llmModal .form-row {
      display: flex;
      flex-direction: column;
      gap: 6px;
      margin: 12px 0
    }

    #llmModal label {
      font-weight: 500;
      font-size: 13px
    }

    #llmModal textarea {
      min-height: 100px
    }

    #llmModal .hint {
      font-size: 12px;
      color: var(--muted);
      margin-top: 4px
    }

    /* toast */
    .toast {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #212734;
      color: var(--text);
      padding: 10px 14px;
      border-radius: 10px;
      border: 1px solid #2c3443;
      z-index: 99
    }

    /* --- Pin the right column to the viewport edge --- */
    #split {
      display: flex;
      height: 100%;
      width: 100%;
    }

    #left {
      flex: 0 0 auto;
      /* left takes only what it needs (Split.js sets size) */
      min-width: 260px;
      /* keep your floor */
    }

    #right {
      flex: 1 1 auto;
      /* right fills the rest */
      min-width: 0;
      /* CRUCIAL: allow shrinking; prevents the phantom gap */
      overflow: auto;
      /* keep internal scrolling */
    }

    /* If you want zero visual gutter on the far right, remove section padding: */
    section#right {
      padding-right: 0;
    }

    /* accessibility patches */
    .small{ color: #bac2d6; }               /* was #a9b1c3 */
    .badge{ color:#d6e1ff; border-color:#253043; }
    .badge.err{ color:#ffdadd; }
    :root{ color-scheme: dark; }            /* hints to OS/browser */

  </style>

  <!-- Prism for YAML/JSON highlighting -->
  <link rel="stylesheet" href="https://unpkg.com/prismjs/themes/prism-tomorrow.min.css">
  <script src="https://unpkg.com/prismjs/prism.js"></script>
  <script src="https://unpkg.com/prismjs/components/prism-yaml.min.js"></script>
  <script src="https://unpkg.com/prismjs/components/prism-json.min.js"></script>

  <!-- Split.js (resizable panes) + SortableJS (drag to reorder) -->
  <script src="https://unpkg.com/split.js/dist/split.min.js"></script>
  <script src="https://unpkg.com/sortablejs@1.15.2/Sortable.min.js"></script>
</head>

<body>
  <header class="toolbar">
    <h1>Truth Capsule Prompt Composer</h1>
    <div class="small" style="font-size:12px; margin-top:5px;">Generated 2025-11-08T18:52:28.726620Z</div>
    <div style="margin-left:auto;display:flex;gap:8px;align-items:center">
      <button  class="btn" id="composeBtn" title="Compose (Ctrl/Cmd+Enter)">üü¢ Compose</button>
      <button class="btn" id="copyBtn" title="Copy prompt">üìã Copy Prompt</button>
      <button class="btn" id="copyLlmBtn" title="Copy LLM command">üíª Copy LLM Bash</button>
      <button class="btn" id="dlBtn" title="Download prompt">‚¨áÔ∏è Download Prompt</button>
      <button class="btn" id="dlJsonBtn" title="Download manifest JSON">‚¨áÔ∏è Download JSON Manifest</button>
      <button class="btn" id="loadJsonBtn" title="Load manifest JSON">‚¨ÜÔ∏è Load JSON Manifest</button>
      <button class="btn" id="shareLinkBtn" title="Copy shareable link">üìã Share Deeplink</button>
      <button class="btn" id="validateAllBtn" title="Validate digests for selected">üîê Validate Digests</button>
      <button class="btn warn" id="clearBtn" title="Clear selection">üóëÔ∏è Clear Capsules</button>
    </div>
  </header>

  <main>
    <div id="split">
      <!-- LEFT COLUMN -->
      <aside id="left">
        <div id="leftTop">
          <input id="search" type="text" placeholder="Filter by id/title/domain/statement‚Ä¶" style="width:100%">
          <div class="row" style="margin-top:10px">
            <label>PROFILES</label>
            <select id="profiles"></select>
          </div>
          <div class="row small" id="profileHelp" style="margin-top:4px"></div>
        </div>

        <!-- RESIZABLE HORIZONTAL SPLIT: Bundles ‚ü∑ Capsules -->
        <div id="leftSplit">
          <div id="bundlesWrap" class="section-block">
            <div class="section-title">BUNDLES (<span id="bundlesCount">0</span>)</div>
            <div id="bundles" class="list"></div>
          </div>
          <div id="capsulesWrap" class="section-block">
            <div class="section-title">CAPSULES (<span id="capsulesCount">0</span>)</div>
            <div id="capsules" class="list"></div>
          </div>
        </div>
      </aside>

      <!-- RIGHT COLUMN -->
      <section id="right">
        <div class="card">
          <div class="row">
            <label style="display:none;"><input type="checkbox" id="includePed" checked> include pedagogy</label>
            <label><input type="checkbox" id="markdown"> markdown preview</label>
            <span class="small">Drag to reorder in Preview</span>
          </div>
        </div>

        <div class="card">
          <div class="row" style="justify-content:space-between">
            <strong>COMPOSED SYSTEM PROMPT</strong>
          </div>
          <textarea id="out" style="margin-top:5px;"></textarea>
        </div>

        <div class="card">
          <strong>PREVIEW ‚Äì SELECTED CAPSULES (DRAG TO REORDER)</strong>
          <div id="preview" style="margin-top:5px;" class="list"></div>
        </div>
      </section>
    </div>
  </main>

  <!-- Capsule modal (YAML highlighted) -->
  <div id="modal">
    <div class="modal-inner">
      <div style="display:flex;justify-content:space-between;align-items:center">
        <strong id="m_title">Capsule</strong>
        <button class="btn small" id="m_close">Close</button>
      </div>
      <div class="row" style="margin:6px 0">
        <button class="btn small" id="m_copy_yaml">Copy YAML</button>
        <button class="btn small" id="m_copy_prov">Copy Provenance</button>
        <button class="btn small" id="m_validate">Validate Digest</button>
        <span id="m_result" class="badge">idle</span>
      </div>
      <pre><code id="m_body_code" class="language-yaml"></code></pre>
    </div>
  </div>

  <!-- LLM Command modal -->
  <div id="llmModal">
    <div class="modal-inner">
      <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:12px">
        <strong>Copy LLM Command</strong>
        <div style="margin-top:-3px; font-weight:bolder;">‚ö†Ô∏è bash only - requires the awesome <a style="color:#7aa2ff"
            target="_blank" href="https://llm.datasette.io/en/stable/">llm</a> python package</div>
        <button class="btn small" id="llm_close">Close</button>
      </div>

      <div class="form-row">
        <label for="llm_template">Template:</label>
        <select id="llm_template"></select>
        <div class="hint" id="llm_template_desc"></div>
      </div>

      <div class="form-row" id="llm_input_row">
        <label for="llm_user_input">User input:</label>
        <textarea id="llm_user_input" placeholder="Enter your prompt/question here..."></textarea>
        <div class="hint" id="llm_input_hint"></div>
      </div>

      <div class="form-row" id="llm_file_row" style="display:none">
        <label for="llm_file_path">File path:</label>
        <input type="text" id="llm_file_path" placeholder="/path/to/input.txt" value="input.txt">
      </div>

      <div class="form-row">
        <label>
          <input type="checkbox" id="llm_minify">
          Minify system prompt (collapse whitespace to single line)
        </label>
        <div class="hint">Minification removes newlines and extra spaces. May affect formatting.</div>
      </div>

      <div class="form-row">
        <label for="llm_preview">Generated command:</label>
        <textarea id="llm_preview" readonly
          style="min-height:200px;font-family:monospace;font-size:12px;background:var(--bg);color:#00ff68;"></textarea>
        <div class="hint">This is what will be copied to your clipboard</div>
      </div>

      <div style="display:flex;gap:8px;margin-top:12px">
        <button class="btn" id="llm_copy">üìã Copy Command</button>
        <button class="btn" id="llm_save">üíæ Save Script</button>
        <button class="btn" id="llm_cancel">Cancel</button>
      </div>
    </div>
  </div>

  <script id="tc-data" type="application/json">{
  "capsules": {
    "llm.citation_required_v1": {
      "id": "llm.citation_required_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Citations required",
      "statement": "Answers must include at least one citation or abstain.",
      "assumptions": [
        "Operating in a general context"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What evidence supports this claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "0a51607ced8bd646d4a3bcaf8fa3c8ef4c5519afe87615669c6ad389d725cb39",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.citation_required_v1.yaml",
      "_raw": "id: llm.citation_required_v1\nversion: 1.0.0\ndomain: llm\ntitle: Citations required\nstatement: Answers must include at least one citation or abstain.\nassumptions:\n- Operating in a general context\npedagogy:\n- kind: Socratic\n  text: What evidence supports this claim?\n- kind: Aphorism\n  text: Cite or abstain.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 0a51607ced8bd646d4a3bcaf8fa3c8ef4c5519afe87615669c6ad389d725cb39\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.citation_required_v1_signed": {
      "id": "llm.citation_required_v1_signed",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Citations required (signed demo)",
      "statement": "Answers must include at least one citation or abstain.",
      "assumptions": [],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What source supports your key claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "provenance": {
        "author": "Truth Capsules Demo",
        "license": "MIT",
        "schema": "provenance.v1",
        "org": "Truth Capsules",
        "created": "2025-11-07T04:51:20.658919Z",
        "signing": {
          "algorithm": "ed25519",
          "public_key_pem": "-----BEGIN PUBLIC KEY-----\nMCowBQYDK2VwAyEAdkKe+ZblRkk/8oGtvid7tisLS8L3j12LjGHLC05vnDs=\n-----END PUBLIC KEY-----\n",
          "digest": "b7862aabe696451c37f4e870ece9ae18b37344ef14cf48561dbadf40a5bd5d42",
          "signature_b64": "VJ8i2ZLMIER3ITahlPQZ435w/ZxRAwyGRnPqboVQG78+GUe2alcBd5BS/1KzjtzMxi+B32TvaSbu7tYf3rNSBg==",
          "status": "approved"
        }
      },
      "_file": "./capsules/llm.citation_required_v1_signed.yaml",
      "_raw": "id: llm.citation_required_v1_signed\nversion: 1.0.0\ndomain: llm\ntitle: Citations required (signed demo)\nstatement: Answers must include at least one citation or abstain.\nassumptions: []\npedagogy:\n- kind: Socratic\n  text: What source supports your key claim?\n- kind: Aphorism\n  text: Cite or abstain.\nprovenance:\n  author: Truth Capsules Demo\n  license: MIT\n  schema: provenance.v1\n  org: Truth Capsules\n  created: '2025-11-07T04:51:20.658919Z'\n  signing:\n    algorithm: ed25519\n    public_key_pem: '-----BEGIN PUBLIC KEY-----\n\n      MCowBQYDK2VwAyEAdkKe+ZblRkk/8oGtvid7tisLS8L3j12LjGHLC05vnDs=\n\n      -----END PUBLIC KEY-----\n\n      '\n    digest: b7862aabe696451c37f4e870ece9ae18b37344ef14cf48561dbadf40a5bd5d42\n    signature_b64: VJ8i2ZLMIER3ITahlPQZ435w/ZxRAwyGRnPqboVQG78+GUe2alcBd5BS/1KzjtzMxi+B32TvaSbu7tYf3rNSBg==\n    status: approved\n"
    },
    "llm.plan_backtest_v1": {
      "id": "llm.plan_backtest_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Plan Backtest",
      "statement": "Backtest the plan on a prior similar case; report differences and whether the plan would have succeeded.",
      "assumptions": [
        "We can reference at least one analogous case (internal or public)."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What happened last time we tried something like this?"
        },
        {
          "kind": "Aphorism",
          "text": "Yesterday is a cheap simulator."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "ca48eef684d2815426664bd7beb2a8a785586c1c169f991a4e64252a99c4155b",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.plan_backtest_v1.yaml",
      "_raw": "id: llm.plan_backtest_v1\nversion: 1.0.0\ndomain: llm\ntitle: Plan Backtest\nstatement: Backtest the plan on a prior similar case; report differences and whether\n  the plan would have succeeded.\nassumptions:\n- We can reference at least one analogous case (internal or public).\npedagogy:\n- kind: Socratic\n  text: What happened last time we tried something like this?\n- kind: Aphorism\n  text: Yesterday is a cheap simulator.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: ca48eef684d2815426664bd7beb2a8a785586c1c169f991a4e64252a99c4155b\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pr_deploy_checklist_v1": {
      "id": "llm.pr_deploy_checklist_v1",
      "version": "1.0.0",
      "domain": "pr_review",
      "title": "PR Review - Deploy Checklist",
      "statement": "Gate deploy on: feature flag (if risky), migration plan + rollback, observability hooks, on-call acknowledgement.",
      "assumptions": [
        "You can defer large refactors; ship safely first."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "If we had to roll back in 5 minutes, how?"
        },
        {
          "kind": "Aphorism",
          "text": "Plan the rollback before the rollout."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "10679b47e25ea1c981f846f04fc1866994737d7dcc52f8d5888e6774d9debf5f",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pr_deploy_checklist_v1.yaml",
      "_raw": "id: llm.pr_deploy_checklist_v1\nversion: 1.0.0\ndomain: pr_review\ntitle: PR Review - Deploy Checklist\nstatement: 'Gate deploy on: feature flag (if risky), migration plan + rollback, observability\n  hooks, on-call acknowledgement.'\nassumptions:\n- You can defer large refactors; ship safely first.\npedagogy:\n- kind: Socratic\n  text: If we had to roll back in 5 minutes, how?\n- kind: Aphorism\n  text: Plan the rollback before the rollout.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 10679b47e25ea1c981f846f04fc1866994737d7dcc52f8d5888e6774d9debf5f\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pr_test_hints_v1": {
      "id": "llm.pr_test_hints_v1",
      "version": "1.0.0",
      "domain": "pr_review",
      "title": "PR Review - Minimal Tests",
      "statement": "Propose 2‚Äì4 smallest tests that would catch a regression introduced by this diff (include inputs/edges).",
      "assumptions": [
        "Some testing harness exists (unit/integration)."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What‚Äôs the cheapest test that would fail if you‚Äôre wrong?"
        },
        {
          "kind": "Aphorism",
          "text": "One failing test beats ten opinions."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "9a9f2f0b564e7630e4fec39fbe9762f65a5e68eae959ff9038a4a0f014399641",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pr_test_hints_v1.yaml",
      "_raw": "id: llm.pr_test_hints_v1\nversion: 1.0.0\ndomain: pr_review\ntitle: PR Review - Minimal Tests\nstatement: Propose 2‚Äì4 smallest tests that would catch a regression introduced by\n  this diff (include inputs/edges).\nassumptions:\n- Some testing harness exists (unit/integration).\npedagogy:\n- kind: Socratic\n  text: What‚Äôs the cheapest test that would fail if you‚Äôre wrong?\n- kind: Aphorism\n  text: One failing test beats ten opinions.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 9a9f2f0b564e7630e4fec39fbe9762f65a5e68eae959ff9038a4a0f014399641\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pii_redaction_guard_v1": {
      "id": "llm.pii_redaction_guard_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "PII redaction",
      "statement": "Output must not contain raw PII (emails/phones). Use placeholders or abstain.",
      "assumptions": [
        "Operating in a general context"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What evidence supports this claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "87d8414f424427fac995afd8b04e8f7e2ec47d8520c13067cb2117bb40928c60",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pii_redaction_guard_v1.yaml",
      "_raw": "id: llm.pii_redaction_guard_v1\nversion: 1.0.0\ndomain: llm\ntitle: PII redaction\nstatement: Output must not contain raw PII (emails/phones). Use placeholders or abstain.\nassumptions:\n- Operating in a general context\npedagogy:\n- kind: Socratic\n  text: What evidence supports this claim?\n- kind: Aphorism\n  text: Cite or abstain.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 87d8414f424427fac995afd8b04e8f7e2ec47d8520c13067cb2117bb40928c60\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pr_risk_tags_v1": {
      "id": "llm.pr_risk_tags_v1",
      "version": "1.0.0",
      "domain": "pr_review",
      "title": "PR Review - Risk Tags",
      "statement": "Assign risk tags {security, performance, availability, migration, breaking_change, data_loss} with 0‚Äì1 severity and 1‚Äì2 line rationale.",
      "assumptions": [
        "Risk framing helps prioritize deeper review and testing."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Which user/system risk is most plausible here?"
        },
        {
          "kind": "Aphorism",
          "text": "Name the risk, shrink the risk."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "58c5802699d64ffa2632d255638c27617e0b3cbd1be1c7aa5a6d6bba9eff39a2",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pr_risk_tags_v1.yaml",
      "_raw": "id: llm.pr_risk_tags_v1\nversion: 1.0.0\ndomain: pr_review\ntitle: PR Review - Risk Tags\nstatement: Assign risk tags {security, performance, availability, migration, breaking_change,\n  data_loss} with 0‚Äì1 severity and 1‚Äì2 line rationale.\nassumptions:\n- Risk framing helps prioritize deeper review and testing.\npedagogy:\n- kind: Socratic\n  text: Which user/system risk is most plausible here?\n- kind: Aphorism\n  text: Name the risk, shrink the risk.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 58c5802699d64ffa2632d255638c27617e0b3cbd1be1c7aa5a6d6bba9eff39a2\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.evidence_gap_triage_v1": {
      "id": "llm.evidence_gap_triage_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Evidence Gap Triage",
      "statement": "Identify missing evidence blocking a sound answer; request the single smallest artifact that would unlock progress.",
      "assumptions": [
        "The model/user can ask for one clarifying item."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What one artifact would collapse uncertainty the most?"
        },
        {
          "kind": "Aphorism",
          "text": "Ask once, ask small."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "eb49e65eaa19a8197d7f1b38547a7c66c4ba49b81c1bf18718a57135a3d8e1e4",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.evidence_gap_triage_v1.yaml",
      "_raw": "id: llm.evidence_gap_triage_v1\nversion: 1.0.0\ndomain: llm\ntitle: Evidence Gap Triage\nstatement: Identify missing evidence blocking a sound answer; request the single smallest\n  artifact that would unlock progress.\nassumptions:\n- The model/user can ask for one clarifying item.\npedagogy:\n- kind: Socratic\n  text: What one artifact would collapse uncertainty the most?\n- kind: Aphorism\n  text: Ask once, ask small.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: eb49e65eaa19a8197d7f1b38547a7c66c4ba49b81c1bf18718a57135a3d8e1e4\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pr_change_impact_v1": {
      "id": "llm.pr_change_impact_v1",
      "version": "1.0.0",
      "domain": "pr_review",
      "title": "PR Review - Change Impact",
      "statement": "Describe user-facing impact (if any), docs to update, and a single line release note.",
      "assumptions": [
        "Every externally visible change gets a note or is explicitly internal-only."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Who will notice this change tomorrow?"
        },
        {
          "kind": "Aphorism",
          "text": "If it matters, document it."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "cb5ede16f518629a9bb6118a91ad15595d7b72c6bec8952edc9a9deb5fcb0fab",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pr_change_impact_v1.yaml",
      "_raw": "id: llm.pr_change_impact_v1\nversion: 1.0.0\ndomain: pr_review\ntitle: PR Review - Change Impact\nstatement: Describe user-facing impact (if any), docs to update, and a single line\n  release note.\nassumptions:\n- Every externally visible change gets a note or is explicitly internal-only.\npedagogy:\n- kind: Socratic\n  text: Who will notice this change tomorrow?\n- kind: Aphorism\n  text: If it matters, document it.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: cb5ede16f518629a9bb6118a91ad15595d7b72c6bec8952edc9a9deb5fcb0fab\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.counterfactual_probe_v1": {
      "id": "llm.counterfactual_probe_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Counterfactual Probe",
      "statement": "Before concluding, generate 2‚Äì3 counterfactual worlds that would flip the decision; list the observable tests that would distinguish them.",
      "assumptions": [
        "There is uncertainty worth exploring.",
        "Budget allows 1‚Äì3 tiny tests."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What would have to be true for the opposite decision to be best?"
        },
        {
          "kind": "Aphorism",
          "text": "Seek disconfirming evidence first."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "97645585b83080f11a69418850b492fdde87eb8a9e6b4183d5fbb1ee017f569a",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.counterfactual_probe_v1.yaml",
      "_raw": "id: llm.counterfactual_probe_v1\nversion: 1.0.0\ndomain: llm\ntitle: Counterfactual Probe\nstatement: Before concluding, generate 2‚Äì3 counterfactual worlds that would flip the\n  decision; list the observable tests that would distinguish them.\nassumptions:\n- There is uncertainty worth exploring.\n- Budget allows 1‚Äì3 tiny tests.\npedagogy:\n- kind: Socratic\n  text: What would have to be true for the opposite decision to be best?\n- kind: Aphorism\n  text: Seek disconfirming evidence first.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 97645585b83080f11a69418850b492fdde87eb8a9e6b4183d5fbb1ee017f569a\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.red_team_assessment_v1": {
      "id": "llm.red_team_assessment_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Red Team Assessment Protocol",
      "statement": "On a red-team request, perform an adversarial evaluation: clarify objective & asset, list assumptions, identify actors & capabilities, enumerate plausible attacks, show at least one concrete exploit path, rate severity√ólikelihood (0‚Äì1), propose mitigations and a 48‚Äëhour action plan.",
      "assumptions": [
        "The user explicitly requests a red-team assessment for constructive hardening.",
        "Information provided is for defense; do not share sensitive exploit details beyond what is necessary to mitigate.",
        "Follow platform safety policies; redact secrets and PII."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What asset are we protecting and from whom (top 2 threat actors)?"
        },
        {
          "kind": "Socratic",
          "text": "What assumption, if false, makes failure most likely?"
        },
        {
          "kind": "Socratic",
          "text": "What is the cheapest path to impact for an attacker?"
        },
        {
          "kind": "Aphorism",
          "text": "Assume a breach; prove recovery."
        },
        {
          "kind": "Aphorism",
          "text": "Strong claims require strong evidence."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "a7ee80b6f0de049176869e5168f2d9968fbcdd97da2dac47206f46c508fcf942",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.red_team_assessment_v1.yaml",
      "_raw": "id: llm.red_team_assessment_v1\nversion: 1.0.0\ndomain: llm\ntitle: Red Team Assessment Protocol\nstatement: 'On a red-team request, perform an adversarial evaluation: clarify objective\n  & asset, list assumptions, identify actors & capabilities, enumerate plausible attacks,\n  show at least one concrete exploit path, rate severity√ólikelihood (0‚Äì1), propose\n  mitigations and a 48‚Äëhour action plan.'\nassumptions:\n- The user explicitly requests a red-team assessment for constructive hardening.\n- Information provided is for defense; do not share sensitive exploit details beyond\n  what is necessary to mitigate.\n- Follow platform safety policies; redact secrets and PII.\npedagogy:\n- kind: Socratic\n  text: What asset are we protecting and from whom (top 2 threat actors)?\n- kind: Socratic\n  text: What assumption, if false, makes failure most likely?\n- kind: Socratic\n  text: What is the cheapest path to impact for an attacker?\n- kind: Aphorism\n  text: Assume a breach; prove recovery.\n- kind: Aphorism\n  text: Strong claims require strong evidence.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: a7ee80b6f0de049176869e5168f2d9968fbcdd97da2dac47206f46c508fcf942\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.tool_json_contract_v1": {
      "id": "llm.tool_json_contract_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Tool JSON contract",
      "statement": "Tool call args must match the JSON schema (required fields & types).",
      "assumptions": [
        "Operating in a general context"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What evidence supports this claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "1a7282f0873062f269a62fb2de28f3d5971f103b603c87381316e7c1a1161cc0",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.tool_json_contract_v1.yaml",
      "_raw": "id: llm.tool_json_contract_v1\nversion: 1.0.0\ndomain: llm\ntitle: Tool JSON contract\nstatement: Tool call args must match the JSON schema (required fields & types).\nassumptions:\n- Operating in a general context\npedagogy:\n- kind: Socratic\n  text: What evidence supports this claim?\n- kind: Aphorism\n  text: Cite or abstain.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 1a7282f0873062f269a62fb2de28f3d5971f103b603c87381316e7c1a1161cc0\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.five_whys_root_cause_v1": {
      "id": "llm.five_whys_root_cause_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Five Whys (Root Cause)",
      "statement": "Perform a 3‚Äì5 Whys drill; propose a countermeasure for the root cause and one guardrail to prevent regression.",
      "assumptions": [
        "Event or defect is concrete and recent."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Why did this happen? Why was that possible? (repeat)"
        },
        {
          "kind": "Aphorism",
          "text": "Fix the system, not the symptom."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "1bbdd1db6b770ba4b9a73c6fe6e9f9d309cc4524e6edb4105199ce83922bc563",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.five_whys_root_cause_v1.yaml",
      "_raw": "id: llm.five_whys_root_cause_v1\nversion: 1.0.0\ndomain: llm\ntitle: Five Whys (Root Cause)\nstatement: Perform a 3‚Äì5 Whys drill; propose a countermeasure for the root cause and\n  one guardrail to prevent regression.\nassumptions:\n- Event or defect is concrete and recent.\npedagogy:\n- kind: Socratic\n  text: Why did this happen? Why was that possible? (repeat)\n- kind: Aphorism\n  text: Fix the system, not the symptom.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 1bbdd1db6b770ba4b9a73c6fe6e9f9d309cc4524e6edb4105199ce83922bc563\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.judge_answer_quality_v1": {
      "id": "llm.judge_answer_quality_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Judge answer quality",
      "statement": "LLM-judge must score >= 0.8 with JSON {score, verdict, justification}.",
      "assumptions": [
        "Operating in a general context"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What evidence supports this claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "8ae3b7c3603d54649baccf26fda915dc95c28484f04b542962afa8e796995caf",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.judge_answer_quality_v1.yaml",
      "_raw": "id: llm.judge_answer_quality_v1\nversion: 1.0.0\ndomain: llm\ntitle: Judge answer quality\nstatement: LLM-judge must score >= 0.8 with JSON {score, verdict, justification}.\nassumptions:\n- Operating in a general context\npedagogy:\n- kind: Socratic\n  text: What evidence supports this claim?\n- kind: Aphorism\n  text: Cite or abstain.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 8ae3b7c3603d54649baccf26fda915dc95c28484f04b542962afa8e796995caf\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.safety_refusal_guard_v1": {
      "id": "llm.safety_refusal_guard_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Safety & Refusal Guard",
      "statement": "If a request risks policy or safety violations, refuse with a brief reason and offer the closest safe alternative.",
      "assumptions": [
        "Policies and safety priorities apply to this context."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What is the minimal safe deliverable that still helps?"
        },
        {
          "kind": "Aphorism",
          "text": "Refuse early, redirect helpfully."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "fc210d0ff24f4f0b6ab7eb320d7c008a30f4a558170b78ae50fc73642b48a7bb",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.safety_refusal_guard_v1.yaml",
      "_raw": "id: llm.safety_refusal_guard_v1\nversion: 1.0.0\ndomain: llm\ntitle: Safety & Refusal Guard\nstatement: If a request risks policy or safety violations, refuse with a brief reason\n  and offer the closest safe alternative.\nassumptions:\n- Policies and safety priorities apply to this context.\npedagogy:\n- kind: Socratic\n  text: What is the minimal safe deliverable that still helps?\n- kind: Aphorism\n  text: Refuse early, redirect helpfully.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: fc210d0ff24f4f0b6ab7eb320d7c008a30f4a558170b78ae50fc73642b48a7bb\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.fermi_estimation_v1": {
      "id": "llm.fermi_estimation_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Fermi Estimation",
      "statement": "Produce an order‚Äëof‚Äëmagnitude estimate with explicit factors, ranges, and resulting uncertainty (log‚Äëscale).",
      "assumptions": [
        "A back‚Äëof‚Äëthe‚Äëenvelope answer is acceptable to guide decision making."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What are the 3‚Äì5 multiplicative factors?"
        },
        {
          "kind": "Aphorism",
          "text": "Be roughly right faster, then refine."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "ff0b085cd83a53d0c4493dc44bfe48847f27d399227bb1abcdf0af3155fd29d8",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.fermi_estimation_v1.yaml",
      "_raw": "id: llm.fermi_estimation_v1\nversion: 1.0.0\ndomain: llm\ntitle: Fermi Estimation\nstatement: Produce an order‚Äëof‚Äëmagnitude estimate with explicit factors, ranges, and\n  resulting uncertainty (log‚Äëscale).\nassumptions:\n- A back‚Äëof‚Äëthe‚Äëenvelope answer is acceptable to guide decision making.\npedagogy:\n- kind: Socratic\n  text: What are the 3‚Äì5 multiplicative factors?\n- kind: Aphorism\n  text: Be roughly right faster, then refine.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: ff0b085cd83a53d0c4493dc44bfe48847f27d399227bb1abcdf0af3155fd29d8\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.pr_diff_first_v1": {
      "id": "llm.pr_diff_first_v1",
      "version": "1.0.0",
      "domain": "pr_review",
      "title": "PR Review - Diff First",
      "statement": "Always read the diff first. Summarize changes in ‚â§5 bullets with file counts and risky areas (auth, I/O, concurrency, migrations).",
      "assumptions": [
        "A textual diff or list of changed files is available.",
        "Goal is actionable review, not style nitpicks."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What actually changed (files, functions, interfaces)?"
        },
        {
          "kind": "Aphorism",
          "text": "Review behavior, not just syntax."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "b519f3cdb754d00b97862fd38de1fd74c389b78f691986f34b65de370bb45d82",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.pr_diff_first_v1.yaml",
      "_raw": "id: llm.pr_diff_first_v1\nversion: 1.0.0\ndomain: pr_review\ntitle: PR Review - Diff First\nstatement: Always read the diff first. Summarize changes in ‚â§5 bullets with file counts\n  and risky areas (auth, I/O, concurrency, migrations).\nassumptions:\n- A textual diff or list of changed files is available.\n- Goal is actionable review, not style nitpicks.\npedagogy:\n- kind: Socratic\n  text: What actually changed (files, functions, interfaces)?\n- kind: Aphorism\n  text: Review behavior, not just syntax.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: b519f3cdb754d00b97862fd38de1fd74c389b78f691986f34b65de370bb45d82\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.bias_checklist_v1": {
      "id": "llm.bias_checklist_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Bias & Mode Collapse Check",
      "statement": "Before finalizing, scan for common failure modes: confirmation bias, selection bias, overconfident tone, mode collapse.",
      "assumptions": [
        "Brief self‚Äëaudit improves reliability."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Which plausible alternative did we ignore?"
        },
        {
          "kind": "Aphorism",
          "text": "Doubt is a feature."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "ac2b51c4e496a89372de921918c2cacd072e548934aaf385f15f9b0678da2dbb",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.bias_checklist_v1.yaml",
      "_raw": "id: llm.bias_checklist_v1\nversion: 1.0.0\ndomain: llm\ntitle: Bias & Mode Collapse Check\nstatement: 'Before finalizing, scan for common failure modes: confirmation bias, selection\n  bias, overconfident tone, mode collapse.'\nassumptions:\n- Brief self‚Äëaudit improves reliability.\npedagogy:\n- kind: Socratic\n  text: Which plausible alternative did we ignore?\n- kind: Aphorism\n  text: Doubt is a feature.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: ac2b51c4e496a89372de921918c2cacd072e548934aaf385f15f9b0678da2dbb\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.plan_verify_answer_v1": {
      "id": "llm.plan_verify_answer_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Plan ‚Üí Verify ‚Üí Answer",
      "statement": "Plan‚ÜíVerify‚ÜíAnswer. The final answer references collected evidence.",
      "assumptions": [
        "Operating in a general context"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What evidence supports this claim?"
        },
        {
          "kind": "Aphorism",
          "text": "Cite or abstain."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "0aab055bc4c1b504cca4d9ddb8be1074a71835c9b3aab076d7c511c425a9664f",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.plan_verify_answer_v1.yaml",
      "_raw": "id: llm.plan_verify_answer_v1\nversion: 1.0.0\ndomain: llm\ntitle: Plan ‚Üí Verify ‚Üí Answer\nstatement: Plan‚ÜíVerify‚ÜíAnswer. The final answer references collected evidence.\nassumptions:\n- Operating in a general context\npedagogy:\n- kind: Socratic\n  text: What evidence supports this claim?\n- kind: Aphorism\n  text: Cite or abstain.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 0aab055bc4c1b504cca4d9ddb8be1074a71835c9b3aab076d7c511c425a9664f\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.assumption_to_test_v1": {
      "id": "llm.assumption_to_test_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Assumptions ‚Üí Tests",
      "statement": "Convert each critical assumption into a falsifiable micro-test with owner, required evidence, and a 24‚Äì72h timebox.",
      "assumptions": [
        "Assumptions are enumerated or can be elicited with one question."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Which single assumption, if wrong, invalidates the plan?"
        },
        {
          "kind": "Aphorism",
          "text": "Make failure explicit and reversible."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "9695ca488e9ab7912ff2e76b08a7205b08fb08627e1cab70fe0caa5fb9f54ed5",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.assumption_to_test_v1.yaml",
      "_raw": "id: llm.assumption_to_test_v1\nversion: 1.0.0\ndomain: llm\ntitle: Assumptions ‚Üí Tests\nstatement: Convert each critical assumption into a falsifiable micro-test with owner,\n  required evidence, and a 24‚Äì72h timebox.\nassumptions:\n- Assumptions are enumerated or can be elicited with one question.\npedagogy:\n- kind: Socratic\n  text: Which single assumption, if wrong, invalidates the plan?\n- kind: Aphorism\n  text: Make failure explicit and reversible.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 9695ca488e9ab7912ff2e76b08a7205b08fb08627e1cab70fe0caa5fb9f54ed5\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "llm.steelmanning_v1": {
      "id": "llm.steelmanning_v1",
      "version": "1.0.0",
      "domain": "llm",
      "title": "Steelmanning",
      "statement": "Before critiquing, restate the strongest version of the opposing view in 3 bullets, then highlight one genuine crux.",
      "assumptions": [
        "There exists an alternative that a reasonable expert could endorse."
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What would a smart critic say against this?"
        },
        {
          "kind": "Aphorism",
          "text": "Steelman before you strike."
        }
      ],
      "witnesses": [],
      "provenance": {
        "schema": "provenance.v1",
        "author": "John Macgregor",
        "org": "Truth Capsules Demo",
        "license": "MIT",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:56:05.351404Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "ba8a2206b3716e290bef35a11a577c7e59bfbb69d9535f640b611e3d4e7e98ee",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/llm.steelmanning_v1.yaml",
      "_raw": "id: llm.steelmanning_v1\nversion: 1.0.0\ndomain: llm\ntitle: Steelmanning\nstatement: Before critiquing, restate the strongest version of the opposing view in\n  3 bullets, then highlight one genuine crux.\nassumptions:\n- There exists an alternative that a reasonable expert could endorse.\npedagogy:\n- kind: Socratic\n  text: What would a smart critic say against this?\n- kind: Aphorism\n  text: Steelman before you strike.\nwitnesses: []\nprovenance:\n  schema: provenance.v1\n  author: John Macgregor\n  org: Truth Capsules Demo\n  license: MIT\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:56:05.351404Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: ba8a2206b3716e290bef35a11a577c7e59bfbb69d9535f640b611e3d4e7e98ee\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "pedagogy.problem_solving_v1": {
      "id": "pedagogy.problem_solving_v1",
      "version": "1.0.0",
      "title": "Five-step problem-solving discipline",
      "domain": "pedagogy",
      "statement": "A valid solution includes: (1) objective, (2) assumptions, (3) plan, (4) evidence, (5) summary with trade-offs and next step.",
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What is the concrete objective and success criteria?"
        },
        {
          "kind": "Aphorism",
          "text": "One small experiment beats a thousand meetings."
        }
      ],
      "witnesses": [
        {
          "name": "five_step_gate",
          "language": "python",
          "code": "import json, os\n\np = os.getenv(\"PS_REPORT\", \"artifacts/examples/problem_solving_ok.json\")\n\nr = json.load(open(p))\n\nneed = [\"objective\",\"assumptions\",\"plan\",\"evidence\",\"summary\"]\n\nmissing = [k for k in need if not r.get(k)]\n\nassert not missing, f\"Missing fields: {missing}\"\n\nassert isinstance(r[\"assumptions\"], list) and len(r[\"assumptions\"])>=1\n\nassert isinstance(r[\"evidence\"], list) and any(len(str(e))>=10 for e in r[\"evidence\"])"
        }
      ],
      "provenance": {
        "author": "Truth Capsules",
        "license": "MIT",
        "schema": "provenance.v1",
        "org": "Truth Capsules Demo",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "b797a413841b047de9564e761934526f7b6b22d98b284aa418d4f2775e099a8a",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/pedagogy/pedagogy.problem_solving_v1.yaml",
      "_raw": "id: pedagogy.problem_solving_v1\nversion: 1.0.0\ntitle: Five-step problem-solving discipline\ndomain: pedagogy\nstatement: 'A valid solution includes: (1) objective, (2) assumptions, (3) plan, (4)\n  evidence, (5) summary with trade-offs and next step.'\npedagogy:\n- kind: Socratic\n  text: What is the concrete objective and success criteria?\n- kind: Aphorism\n  text: One small experiment beats a thousand meetings.\nwitnesses:\n- name: five_step_gate\n  language: python\n  code: 'import json, os\n\n\n    p = os.getenv(\"PS_REPORT\", \"artifacts/examples/problem_solving_ok.json\")\n\n\n    r = json.load(open(p))\n\n\n    need = [\"objective\",\"assumptions\",\"plan\",\"evidence\",\"summary\"]\n\n\n    missing = [k for k in need if not r.get(k)]\n\n\n    assert not missing, f\"Missing fields: {missing}\"\n\n\n    assert isinstance(r[\"assumptions\"], list) and len(r[\"assumptions\"])>=1\n\n\n    assert isinstance(r[\"evidence\"], list) and any(len(str(e))>=10 for e in r[\"evidence\"])'\nprovenance:\n  author: Truth Capsules\n  license: MIT\n  schema: provenance.v1\n  org: Truth Capsules Demo\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: b797a413841b047de9564e761934526f7b6b22d98b284aa418d4f2775e099a8a\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "business.decision_log_v1": {
      "id": "business.decision_log_v1",
      "version": "1.0.0",
      "domain": "business",
      "title": "Decision Log Gate",
      "statement": "Decision records must include decision, ‚â•3 options, ‚â•2 criteria, and a rationale mentioning a trade-off.",
      "assumptions": [
        "Decision records are structured as JSON",
        "Criteria and options can be enumerated"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "Which option best satisfies the stated criteria?"
        },
        {
          "kind": "Aphorism",
          "text": "Make trade-offs explicit, not implicit."
        }
      ],
      "witnesses": [
        {
          "name": "decision_log_gate",
          "language": "python",
          "code": "import json, os\n\np = os.getenv(\"DEC_REPORT\", \"artifacts/examples/decision_log_ok.json\")\n\nr = json.load(open(p))\n\nassert r.get(\"decision\")\n\nassert isinstance(r.get(\"options\"), list) and len(r[\"options\"])>=3\n\nassert isinstance(r.get(\"criteria\"), list) and len(r[\"criteria\"])>=2\n\nassert \"trade-off\" in (r.get(\"rationale\",\"\")+\"\").lower() or \"because\" in (r.get(\"rationale\",\"\")+\"\").lower()"
        }
      ],
      "provenance": {
        "author": "Truth Capsules",
        "license": "MIT",
        "schema": "provenance.v1",
        "org": "Truth Capsules Demo",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "7f5356a5eb951df4478793f0a90c927331e39ae9031e1197236f18e519c331cb",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/business/business.decision_log_v1.yaml",
      "_raw": "id: business.decision_log_v1\nversion: 1.0.0\ndomain: business\ntitle: Decision Log Gate\nstatement: Decision records must include decision, ‚â•3 options, ‚â•2 criteria, and a\n  rationale mentioning a trade-off.\nassumptions:\n- Decision records are structured as JSON\n- Criteria and options can be enumerated\npedagogy:\n- kind: Socratic\n  text: Which option best satisfies the stated criteria?\n- kind: Aphorism\n  text: Make trade-offs explicit, not implicit.\nwitnesses:\n- name: decision_log_gate\n  language: python\n  code: 'import json, os\n\n\n    p = os.getenv(\"DEC_REPORT\", \"artifacts/examples/decision_log_ok.json\")\n\n\n    r = json.load(open(p))\n\n\n    assert r.get(\"decision\")\n\n\n    assert isinstance(r.get(\"options\"), list) and len(r[\"options\"])>=3\n\n\n    assert isinstance(r.get(\"criteria\"), list) and len(r[\"criteria\"])>=2\n\n\n    assert \"trade-off\" in (r.get(\"rationale\",\"\")+\"\").lower() or \"because\" in (r.get(\"rationale\",\"\")+\"\").lower()'\nprovenance:\n  author: Truth Capsules\n  license: MIT\n  schema: provenance.v1\n  org: Truth Capsules Demo\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 7f5356a5eb951df4478793f0a90c927331e39ae9031e1197236f18e519c331cb\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    },
    "ops.rollback_plan_v1": {
      "id": "ops.rollback_plan_v1",
      "version": "1.0.0",
      "domain": "ops",
      "title": "Rollback Plan Required",
      "statement": "Deploy plans must include a rollback step with trigger conditions and owner.",
      "assumptions": [
        "Rollback procedures can be documented in advance",
        "Trigger conditions are measurable"
      ],
      "pedagogy": [
        {
          "kind": "Socratic",
          "text": "What is the worst-case failure mode, and how do we reverse it?"
        },
        {
          "kind": "Aphorism",
          "text": "Make failure explicit and reversible."
        }
      ],
      "witnesses": [
        {
          "name": "rollback_present",
          "language": "python",
          "code": "import json, os\n\np = os.getenv(\"OPS_PLAN\", \"artifacts/examples/ops_plan_ok.json\")\n\nr = json.load(open(p))\n\nrb = r.get(\"rollback\", {})\n\nassert rb.get(\"steps\") and rb.get(\"trigger\") and rb.get(\"owner\"), \"Rollback incomplete\""
        }
      ],
      "provenance": {
        "author": "Truth Capsules",
        "license": "MIT",
        "schema": "provenance.v1",
        "org": "Truth Capsules Demo",
        "source_url": "https://example.com/truth-capsules",
        "created": "2025-11-07T03:53:50.511776Z",
        "updated": "2025-11-07T03:56:05.351404Z",
        "review": {
          "status": "draft",
          "reviewers": [],
          "last_reviewed": null
        },
        "signing": {
          "method": "ed25519",
          "key_id": null,
          "pubkey": null,
          "digest": "7be5f47e5ffd7349c81b50a6e46736573221a938df472aa94fc842ff06eedafe",
          "signature": null
        }
      },
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "dependencies": [],
      "incompatible_with": [],
      "security": {
        "sensitivity": "low",
        "notes": ""
      },
      "_file": "./capsules/ops/ops.rollback_plan_v1.yaml",
      "_raw": "id: ops.rollback_plan_v1\nversion: 1.0.0\ndomain: ops\ntitle: Rollback Plan Required\nstatement: Deploy plans must include a rollback step with trigger conditions and owner.\nassumptions:\n- Rollback procedures can be documented in advance\n- Trigger conditions are measurable\npedagogy:\n- kind: Socratic\n  text: What is the worst-case failure mode, and how do we reverse it?\n- kind: Aphorism\n  text: Make failure explicit and reversible.\nwitnesses:\n- name: rollback_present\n  language: python\n  code: 'import json, os\n\n\n    p = os.getenv(\"OPS_PLAN\", \"artifacts/examples/ops_plan_ok.json\")\n\n\n    r = json.load(open(p))\n\n\n    rb = r.get(\"rollback\", {})\n\n\n    assert rb.get(\"steps\") and rb.get(\"trigger\") and rb.get(\"owner\"), \"Rollback incomplete\"'\nprovenance:\n  author: Truth Capsules\n  license: MIT\n  schema: provenance.v1\n  org: Truth Capsules Demo\n  source_url: https://example.com/truth-capsules\n  created: '2025-11-07T03:53:50.511776Z'\n  updated: '2025-11-07T03:56:05.351404Z'\n  review:\n    status: draft\n    reviewers: []\n    last_reviewed: null\n  signing:\n    method: ed25519\n    key_id: null\n    pubkey: null\n    digest: 7be5f47e5ffd7349c81b50a6e46736573221a938df472aa94fc842ff06eedafe\n    signature: null\napplies_to:\n- conversation\n- code_assistant\n- ci\ndependencies: []\nincompatible_with: []\nsecurity:\n  sensitivity: low\n  notes: ''\n"
    }
  },
  "bundles": {
    "test_v1_1_bundle": {
      "name": "test_v1_1_bundle",
      "version": "1.1.0",
      "description": "Test bundle for v1.1 features: priority overrides, exclusions, safety + quality gates.",
      "applies_to": [
        "conversation",
        "code_assistant"
      ],
      "capsules": [
        "llm.safety_refusal_guard_v1",
        "llm.pii_redaction_guard_v1",
        "llm.citation_required_v1",
        "llm.plan_verify_answer_v1",
        "llm.red_team_assessment_v1"
      ],
      "excludes": [
        "llm.red_team_assessment_v1"
      ],
      "priority_overrides": {
        "llm.citation_required_v1": 10,
        "llm.plan_verify_answer_v1": 1
      },
      "order": [
        "llm.plan_verify_answer_v1",
        "llm.safety_refusal_guard_v1",
        "llm.citation_required_v1"
      ],
      "projection": "",
      "tags": [
        "test",
        "v1.1",
        "example"
      ],
      "notes": "This is a test bundle demonstrating all v1.1 features:\n- version field\n- excludes (removes red_team_assessment)\n- priority_overrides (swaps priorities)\n- order (explicit ordering)\n- tags and notes\n",
      "env": {},
      "secrets": [],
      "_file": "./bundles/test_v1_1_bundle.yaml"
    },
    "conversation_pedagogy_v1": {
      "name": "conversation_pedagogy_v1",
      "version": "1.0.0",
      "description": "Pedagogical guidance for problem-solving conversations: Socratic method, explicit reasoning steps.",
      "applies_to": [
        "conversation"
      ],
      "capsules": [
        "pedagogy.problem_solving_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {
        "PS_REPORT": "artifacts/examples/problem_solving_ok.json"
      },
      "secrets": [],
      "_file": "./bundles/conversation_pedagogy_v1.yaml"
    },
    "ci_nonllm_baseline_v1": {
      "name": "ci_nonllm_baseline_v1",
      "version": "1.0.0",
      "description": "Non-LLM business rules for CI: decision log validation, rollback plan requirements.",
      "applies_to": [
        "ci"
      ],
      "capsules": [
        "business.decision_log_v1",
        "ops.rollback_plan_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {
        "DEC_REPORT": "artifacts/examples/decision_log_ok.json",
        "OPS_PLAN": "artifacts/examples/ops_plan_ok.json"
      },
      "secrets": [],
      "_file": "./bundles/ci_nonllm_baseline_v1.yaml"
    },
    "pr_review_minibundle_v1": {
      "name": "pr_review_minibundle_v1",
      "version": "1.0.0",
      "description": "PR review essentials: diff-first analysis, risk tags, test hints, deploy checklist, and change impact.",
      "applies_to": [
        "conversation",
        "code_assistant",
        "ci"
      ],
      "capsules": [
        "llm.pr_diff_first_v1",
        "llm.pr_risk_tags_v1",
        "llm.pr_test_hints_v1",
        "llm.pr_deploy_checklist_v1",
        "llm.pr_change_impact_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {},
      "secrets": [],
      "_file": "./bundles/pr_review_minibundle_v1.yaml"
    },
    "ci_llm_baseline_v1": {
      "name": "ci_llm_baseline_v1",
      "version": "1.0.0",
      "description": "CI/CD LLM quality gates: citations, JSON contracts, answer quality judging, PII scanning.",
      "applies_to": [
        "ci"
      ],
      "capsules": [
        "llm.citation_required_v1",
        "llm.tool_json_contract_v1",
        "llm.plan_verify_answer_v1",
        "llm.pii_redaction_guard_v1",
        "llm.judge_answer_quality_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {
        "TC_ARTIFACT": "artifacts/out/answers.json",
        "TC_SCHEMA": "artifacts/examples/tool_schema_book_meeting.json",
        "TC_CALL": "artifacts/out/tool_calls.json",
        "TC_PVA": "artifacts/out/pva_logs.json",
        "TC_TXT": "artifacts/out/pii_scan.json",
        "TC_CANDIDATE": "artifacts/out/answer_candidate.json",
        "TC_JUDGMENT": "artifacts/judgments/answers.judgment.json"
      },
      "secrets": [
        "OPENAI_API_KEY"
      ],
      "_file": "./bundles/ci_llm_baseline_v1.yaml"
    },
    "assistant_baseline_v1": {
      "name": "assistant_baseline_v1",
      "version": "1.0.0",
      "description": "Core assistant rules: citation required, JSON contract validation, plan-verify-answer, PII redaction.",
      "applies_to": [
        "assistant"
      ],
      "capsules": [
        "llm.citation_required_v1",
        "llm.tool_json_contract_v1",
        "llm.plan_verify_answer_v1",
        "llm.pii_redaction_guard_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {
        "TC_ARTIFACT": "artifacts/examples/answer_with_citation.json",
        "TC_SCHEMA": "artifacts/examples/tool_schema_book_meeting.json",
        "TC_CALL": "artifacts/examples/tool_call_ok.json",
        "TC_PVA": "artifacts/examples/pva_ok.json",
        "TC_TXT": "artifacts/examples/pii_ok.json"
      },
      "secrets": [],
      "_file": "./bundles/assistant_baseline_v1.yaml"
    },
    "conversation_red_team_baseline_v1": {
      "name": "conversation_red_team_baseline_v1",
      "version": "1.0.0",
      "description": "Red-team baseline for conversational AI: probes assumptions, bias, counterfactuals, and safety refusals.",
      "applies_to": [
        "conversation",
        "code_assistant"
      ],
      "capsules": [
        "llm.red_team_assessment_v1",
        "llm.counterfactual_probe_v1",
        "llm.assumption_to_test_v1",
        "llm.steelmanning_v1",
        "llm.five_whys_root_cause_v1",
        "llm.fermi_estimation_v1",
        "llm.safety_refusal_guard_v1",
        "llm.evidence_gap_triage_v1",
        "llm.bias_checklist_v1",
        "llm.plan_backtest_v1"
      ],
      "excludes": [],
      "priority_overrides": {},
      "order": [],
      "projection": "",
      "tags": [],
      "notes": "",
      "env": {},
      "secrets": [],
      "_file": "./bundles/conversation_red_team_baseline_v1.yaml"
    }
  },
  "profiles": {
    "profile.conversational_guidance_v1": {
      "id": "profile.conversational_guidance_v1",
      "title": "Conversational Guidance",
      "version": "1.0.0",
      "description": "In-chat Q&A with reasoning guardrails; natural language output.",
      "response": {
        "format": "natural",
        "policy": "Cite or abstain; follow Plan‚ÜíVerify‚ÜíAnswer; ask ONE crisp follow-up if required.\n",
        "system_block": "SYSTEM: Profile=Conversational Guidance\nPOLICY: Cite or abstain; follow Plan‚ÜíVerify‚ÜíAnswer; ask ONE crisp follow-up if required.\nFORMAT: Natural language (no JSON required).\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:5]",
            "pedagogy.socratic[:3]",
            "pedagogy.aphorisms[:3]"
          ],
          "render": {
            "capsule_header": "BEGIN CAPSULE id={id} version={version} domain={domain}",
            "assumption_bullet": "  - {text}",
            "socratic_bullet": "  - {text}",
            "aphorism_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info."
          }
        }
      },
      "download": {
        "suggested_ext": "txt"
      },
      "_file": "./profiles/conversational.yaml",
      "_raw": "kind: profile\nid: profile.conversational_guidance_v1\ntitle: Conversational Guidance\nversion: 1.0.0\ndescription: In-chat Q&A with reasoning guardrails; natural language output.\nresponse:\n  format: natural\n  policy: |\n    Cite or abstain; follow Plan‚ÜíVerify‚ÜíAnswer; ask ONE crisp follow-up if required.\n  system_block: |\n    SYSTEM: Profile=Conversational Guidance\n    POLICY: Cite or abstain; follow Plan‚ÜíVerify‚ÜíAnswer; ask ONE crisp follow-up if required.\n    FORMAT: Natural language (no JSON required).\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:5]\n      - pedagogy.socratic[:3]\n      - pedagogy.aphorisms[:3]\n    render:\n      capsule_header: \"BEGIN CAPSULE id={id} version={version} domain={domain}\"\n      assumption_bullet: \"  - {text}\"\n      socratic_bullet: \"  - {text}\"\n      aphorism_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.\"\ndownload:\n  suggested_ext: txt\n"
    },
    "profile.tool_runner_v1": {
      "id": "profile.tool_runner_v1",
      "title": "Tool Runner / Function Caller",
      "version": "1.0.0",
      "description": "Produce ONLY JSON arguments for a tool; ask one clarifier if fields missing.",
      "response": {
        "format": "json",
        "policy": "Output only the JSON arguments matching the tool schema. If fields are missing, ask ONE clarifying question.\n",
        "system_block": "SYSTEM: Profile=Tool Runner\nPOLICY: Output ONLY the JSON arguments matching the tool schema. If missing fields, ask ONE clarifying question.\nFORMAT: JSON only.\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:3]"
          ],
          "render": {
            "capsule_header": "BEGIN CAPSULE id={id} version={version} domain={domain}",
            "assumption_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info."
          }
        }
      },
      "download": {
        "suggested_ext": "json"
      },
      "_file": "./profiles/tool_runner.yaml",
      "_raw": "kind: profile\nid: profile.tool_runner_v1\ntitle: Tool Runner / Function Caller\nversion: 1.0.0\ndescription: Produce ONLY JSON arguments for a tool; ask one clarifier if fields missing.\nresponse:\n  format: json\n  policy: |\n    Output only the JSON arguments matching the tool schema. If fields are missing, ask ONE clarifying question.\n  system_block: |\n    SYSTEM: Profile=Tool Runner\n    POLICY: Output ONLY the JSON arguments matching the tool schema. If missing fields, ask ONE clarifying question.\n    FORMAT: JSON only.\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:3]\n    render:\n      capsule_header: \"BEGIN CAPSULE id={id} version={version} domain={domain}\"\n      assumption_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.\"\ndownload:\n  suggested_ext: json\n"
    },
    "profile.ci_llm_judge_v1": {
      "id": "profile.ci_llm_judge_v1",
      "title": "CI Gate - LLM Judge",
      "version": "1.0.0",
      "description": "LLM evaluates artifacts; score + verdict + justification + citations.",
      "response": {
        "format": "json",
        "policy": "Score 0‚Äì1; verdict in {pass,fail}; brief justification; cite or abstain.\n",
        "schema_ref": "judge.schema.v1",
        "rubric": [
          "Factual",
          "Reproducible evidence",
          "Citations present (or abstain)"
        ],
        "system_block": "SYSTEM: Profile=CI LLM Judge\nPOLICY: Score 0‚Äì1; verdict in {pass,fail}; brief justification; cite or abstain.\nSCHEMA: See JUDGE_SCHEMA below.\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:2]"
          ],
          "render": {
            "capsule_header": "CAPSULE: {id} v{version}",
            "assumption_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Obey or abstain."
          }
        }
      },
      "download": {
        "suggested_ext": "json"
      },
      "_file": "./profiles/ci_llm_judge.yaml",
      "_raw": "kind: profile\nid: profile.ci_llm_judge_v1\ntitle: CI Gate - LLM Judge\nversion: 1.0.0\ndescription: LLM evaluates artifacts; score + verdict + justification + citations.\nresponse:\n  format: json\n  policy: |\n    Score 0‚Äì1; verdict in {pass,fail}; brief justification; cite or abstain.\n  schema_ref: judge.schema.v1\n  rubric:\n    - Factual\n    - Reproducible evidence\n    - Citations present (or abstain)\n  system_block: |\n    SYSTEM: Profile=CI LLM Judge\n    POLICY: Score 0‚Äì1; verdict in {pass,fail}; brief justification; cite or abstain.\n    SCHEMA: See JUDGE_SCHEMA below.\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:2]\n    render:\n      capsule_header: \"CAPSULE: {id} v{version}\"\n      assumption_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Obey or abstain.\"\ndownload:\n  suggested_ext: json\n"
    },
    "profile.code_patch_v1": {
      "id": "profile.code_patch_v1",
      "title": "Code Assistant - Patch/PR",
      "version": "1.0.0",
      "description": "Emit minimal unified diff first; rationale after.",
      "response": {
        "format": "diff",
        "policy": "Produce a minimal unified diff; no prose before the diff. Rationale after the fence.\n",
        "system_block": "SYSTEM: Profile=Code Patch\nPOLICY: Produce a minimal unified diff; no prose before the diff. Rationale after.\nFORMAT: First block is ```diff ‚Ä¶``` then a short rationale.\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:3]",
            "pedagogy.socratic[:2]",
            "pedagogy.aphorisms[:2]"
          ],
          "render": {
            "capsule_header": "BEGIN CAPSULE id={id} version={version} domain={domain}",
            "assumption_bullet": "  - {text}",
            "socratic_bullet": "  - {text}",
            "aphorism_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info."
          }
        }
      },
      "download": {
        "suggested_ext": "txt"
      },
      "_file": "./profiles/code_patch.yaml",
      "_raw": "kind: profile\nid: profile.code_patch_v1\ntitle: Code Assistant - Patch/PR\nversion: 1.0.0\ndescription: Emit minimal unified diff first; rationale after.\nresponse:\n  format: diff\n  policy: |\n    Produce a minimal unified diff; no prose before the diff. Rationale after the fence.\n  system_block: |\n    SYSTEM: Profile=Code Patch\n    POLICY: Produce a minimal unified diff; no prose before the diff. Rationale after.\n    FORMAT: First block is ```diff ‚Ä¶``` then a short rationale.\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:3]\n      - pedagogy.socratic[:2]\n      - pedagogy.aphorisms[:2]\n    render:\n      capsule_header: \"BEGIN CAPSULE id={id} version={version} domain={domain}\"\n      assumption_bullet: \"  - {text}\"\n      socratic_bullet: \"  - {text}\"\n      aphorism_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.\"\ndownload:\n  suggested_ext: txt\n"
    },
    "profile.ci_deterministic_gate_v1": {
      "id": "profile.ci_deterministic_gate_v1",
      "title": "CI Gate - Deterministic",
      "version": "1.0.0",
      "description": "Non-LLM checks in CI; machine-parsed JSON pass/fail.",
      "response": {
        "format": "json",
        "policy": "Output JSON only. No extra text.\n",
        "schema_ref": "report.schema.v1",
        "system_block": "SYSTEM: Profile=CI Deterministic Gate\nPOLICY: Output JSON only. No extra text.\nSCHEMA: See REPORT_SCHEMA below.\n",
        "projection": {
          "include": [
            "title",
            "statement"
          ],
          "render": {
            "capsule_header": "CAPSULE: {id} v{version}",
            "enforcement_footer": "ENFORCEMENT: Obey or abstain."
          }
        }
      },
      "download": {
        "suggested_ext": "json"
      },
      "_file": "./profiles/ci_det.yaml",
      "_raw": "kind: profile\nid: profile.ci_deterministic_gate_v1\ntitle: CI Gate - Deterministic\nversion: 1.0.0\ndescription: Non-LLM checks in CI; machine-parsed JSON pass/fail.\nresponse:\n  format: json\n  policy: |\n    Output JSON only. No extra text.\n  schema_ref: report.schema.v1\n  system_block: |\n    SYSTEM: Profile=CI Deterministic Gate\n    POLICY: Output JSON only. No extra text.\n    SCHEMA: See REPORT_SCHEMA below.\n  projection:\n    include:\n      - title\n      - statement\n    render:\n      capsule_header: \"CAPSULE: {id} v{version}\"\n      enforcement_footer: \"ENFORCEMENT: Obey or abstain.\"\ndownload:\n  suggested_ext: json\n"
    },
    "profile.pedagogical_v1": {
      "id": "profile.pedagogical_v1",
      "title": "Pedagogical / Socratic",
      "version": "1.0.0",
      "description": "Teaching/coaching mode; questions first, then takeaways.",
      "response": {
        "format": "natural",
        "policy": "Use 3‚Äì5 Socratic questions, then 3 concise takeaways. Prefer tiny, reversible steps.\n",
        "system_block": "SYSTEM: Profile=Pedagogical\nPOLICY: Use 3‚Äì5 Socratic questions, then 3 bullet takeaways.\nFORMAT: Bulleted text; no JSON.\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:5]",
            "pedagogy.socratic[:5]",
            "pedagogy.aphorisms[:5]"
          ],
          "render": {
            "capsule_header": "BEGIN CAPSULE id={id} version={version} domain={domain}",
            "assumption_bullet": "  - {text}",
            "socratic_bullet": "  - {text}",
            "aphorism_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info."
          }
        }
      },
      "download": {
        "suggested_ext": "md"
      },
      "_file": "./profiles/pedagogical.yaml",
      "_raw": "kind: profile\nid: profile.pedagogical_v1\ntitle: Pedagogical / Socratic\nversion: 1.0.0\ndescription: Teaching/coaching mode; questions first, then takeaways.\nresponse:\n  format: natural\n  policy: |\n    Use 3‚Äì5 Socratic questions, then 3 concise takeaways. Prefer tiny, reversible steps.\n  system_block: |\n    SYSTEM: Profile=Pedagogical\n    POLICY: Use 3‚Äì5 Socratic questions, then 3 bullet takeaways.\n    FORMAT: Bulleted text; no JSON.\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:5]\n      - pedagogy.socratic[:5]\n      - pedagogy.aphorisms[:5]\n    render:\n      capsule_header: \"BEGIN CAPSULE id={id} version={version} domain={domain}\"\n      assumption_bullet: \"  - {text}\"\n      socratic_bullet: \"  - {text}\"\n      aphorism_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.\"\ndownload:\n  suggested_ext: md\n"
    },
    "profile.rules_generator_v1": {
      "id": "profile.rules_generator_v1",
      "title": "Code Assistant - Rules Generator",
      "version": "1.0.0",
      "description": "Emit a single YAML document for agent/IDE rules.",
      "response": {
        "format": "yaml",
        "policy": "Emit one YAML with sections: rules, violations, meta. No prose outside YAML.\n",
        "system_block": "SYSTEM: Profile=Rules Generator\nPOLICY: Emit a single YAML document with 'rules', 'violations', and 'meta' sections.\nFORMAT: ```yaml``` only.\n",
        "projection": {
          "include": [
            "title",
            "statement",
            "assumptions[:3]",
            "pedagogy.socratic[:3]",
            "pedagogy.aphorisms[:2]"
          ],
          "render": {
            "capsule_header": "BEGIN CAPSULE id={id} version={version} domain={domain}",
            "assumption_bullet": "  - {text}",
            "socratic_bullet": "  - {text}",
            "aphorism_bullet": "  - {text}",
            "enforcement_footer": "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info."
          }
        }
      },
      "download": {
        "suggested_ext": "yaml"
      },
      "_file": "./profiles/rules_gen.yaml",
      "_raw": "kind: profile\nid: profile.rules_generator_v1\ntitle: Code Assistant - Rules Generator\nversion: 1.0.0\ndescription: Emit a single YAML document for agent/IDE rules.\nresponse:\n  format: yaml\n  policy: |\n    Emit one YAML with sections: rules, violations, meta. No prose outside YAML.\n  system_block: |\n    SYSTEM: Profile=Rules Generator\n    POLICY: Emit a single YAML document with 'rules', 'violations', and 'meta' sections.\n    FORMAT: ```yaml``` only.\n  projection:\n    include:\n      - title\n      - statement\n      - assumptions[:3]\n      - pedagogy.socratic[:3]\n      - pedagogy.aphorisms[:2]\n    render:\n      capsule_header: \"BEGIN CAPSULE id={id} version={version} domain={domain}\"\n      assumption_bullet: \"  - {text}\"\n      socratic_bullet: \"  - {text}\"\n      aphorism_bullet: \"  - {text}\"\n      enforcement_footer: \"ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.\"\ndownload:\n  suggested_ext: yaml\n"
    }
  },
  "schemas": {},
  "llm_templates": [
    {
      "id": "anthropic_sonnet_chat",
      "label": "Anthropic: Claude 3.5 Sonnet (chat)",
      "model": "anthropic:claude-3-5-sonnet",
      "description": "Chat completion; user input via stdin pipe.",
      "engine": "llm",
      "input_mode": "stdin",
      "extra_flags": [
        "--no-stream"
      ],
      "cmd_template": "{{SYS_HEREDOC}}\n{{STDIN_PIPE}} llm -m {{MODEL}} --system \"$TC_SYSTEM\" {{EXTRA_FLAGS}}\n"
    },
    {
      "id": "ollama_llama3_local",
      "label": "Ollama: llama3 (local)",
      "model": "ollama:llama3",
      "description": "Local model; file input.",
      "engine": "llm",
      "input_mode": "file",
      "extra_flags": [],
      "cmd_template": "{{SYS_HEREDOC}}\nllm -m {{MODEL}} --system \"$TC_SYSTEM\" {{EXTRA_FLAGS}} {{FILE_PATH}}\n"
    },
    {
      "id": "openai_gpt4o_chat",
      "label": "OpenAI: GPT-4o mini (chat)",
      "model": "gpt-4o-mini",
      "description": "Chat completion; user input as arg.",
      "engine": "llm",
      "input_mode": "arg",
      "extra_flags": [],
      "cmd_template": "{{SYS_HEREDOC}}\nllm -m {{MODEL}} --system \"$TC_SYSTEM\" {{EXTRA_FLAGS}} {{INPUT_FRAGMENT}}\n"
    }
  ]
}</script>

    <script>
      /* ------------ Data ------------ */
      const DATA = JSON.parse(document.getElementById('tc-data').textContent);
    </script>

    <script>
      /* ------------ State & helpers ------------ */
      const STATE = { selectedBundles: new Set(), selectedCaps: new Set(), order: [], manualCaps: new Set(), profile: null, filter: "" };
      const $ = id => document.getElementById(id);
      const esc = s => (s == null ? "" : String(s).replace(/[&<>]/g, m => ({ '&': '&amp;', '<': '&lt;', '>': '&gt;' }[m])));

      /* Toast */
      function toast(msg) {
        const t = document.createElement('div'); t.className = 'toast'; t.textContent = msg; document.body.appendChild(t);
        setTimeout(() => t.remove(), 1800);
      }

      /* Hashing for digest */
      const tenc = s => new TextEncoder().encode(s);
      async function sha256(s) { const buf = await crypto.subtle.digest('SHA-256', tenc(s)); return Array.from(new Uint8Array(buf)).map(b => b.toString(16).padStart(2, '0')).join(''); }
      function canonicalJSON(x) {
        if (Array.isArray(x)) return "[" + x.map(canonicalJSON).join(",") + "]";
        if (x && typeof x === "object") { const keys = Object.keys(x).sort(); return "{" + keys.map(k => JSON.stringify(k) + ":" + canonicalJSON(x[k])).join(",") + "}"; }
        return JSON.stringify(x);
      }
      function coreForDigest(c) {
        return {
          id: c.id, version: c.version, domain: c.domain, title: c.title, statement: c.statement,
          assumptions: Array.isArray(c.assumptions) ? c.assumptions : [],
          pedagogy: Array.isArray(c.pedagogy) ? c.pedagogy.map(p => ({ kind: p.kind, text: p.text })) : []
        };
      }
      function digestCore(c) { return canonicalJSON(coreForDigest(c)); }
      async function validateDigest(c) {
        const have = await sha256(digestCore(c));
        const want = (((c.provenance || {}).signing || {}).digest) || '';
        if (!want) return { ok: true, na: true, have, want };
        return { ok: (have === want), na: false, have, want };
      }
      function badgeDigest(c) {
        const b = document.createElement('span'); b.className = 'badge'; b.textContent = 'digest‚Ä¶';
        validateDigest(c).then(r => {
          if (r.na) { b.textContent = 'digest n/a'; b.title = 'No reference digest in capsule'; return; }
          b.textContent = r.ok ? 'digest‚úì' : 'digest‚úó'; b.className = 'badge ' + (r.ok ? 'ok' : 'err');
          b.title = r.ok ? 'Digest OK' : 'Have ' + r.have + ' want ' + r.want;
        });
        return b;
      }
      function badgeAuthor(c) {
        const p = c.provenance || {}; const b = document.createElement('span'); b.className = 'badge'; b.textContent = (p.author || '?'); return b;
      }

      /* ------------ Modal ------------ */
      let MODAL = null;
      function openModal(title, c) {
        MODAL = c;
        $('m_title').textContent = title;
        $('m_body_code').textContent = (c._raw || '');
        Prism.highlightElement($('m_body_code'));
        $('m_result').textContent = 'idle'; $('m_result').className = 'badge';
        $('modal').style.display = 'flex';
      }
      function closeModal() { $('modal').style.display = 'none'; MODAL = null; }
      $('m_close').addEventListener('click', closeModal);
      $('modal').addEventListener('click', e => { if (e.target && e.target.id === 'modal') closeModal(); });
      $('m_copy_yaml').addEventListener('click', () => { if (!MODAL) return; navigator.clipboard.writeText(MODAL._raw || ''); toast('YAML copied'); });
      $('m_copy_prov').addEventListener('click', () => { if (!MODAL) return; navigator.clipboard.writeText(JSON.stringify(MODAL.provenance || {}, null, 2)); toast('Provenance copied'); });
      $('m_validate').addEventListener('click', async () => { if (!MODAL) return; const r = await validateDigest(MODAL); const tag = $('m_result'); tag.textContent = r.ok ? 'digest‚úì' : 'digest‚úó'; tag.className = 'badge ' + (r.ok ? 'ok' : 'err'); tag.title = r.ok ? 'OK' : ('have:' + r.have + ' want:' + r.want); });

      /* ------------ Renderers ------------ */
      function renderProfiles() {
        const sel = $('profiles'); sel.innerHTML = '';
        const keys = Object.keys(DATA.profiles || {}).sort();
        for (const k of keys) { const p = DATA.profiles[k] || {}; const o = document.createElement('option'); o.value = k; o.textContent = (p.title || k) + ' (' + (p.version || '1.0.0') + ')'; sel.appendChild(o); }
        if (!STATE.profile) STATE.profile = keys[0] || null;
        sel.value = STATE.profile || '';
        $('profileHelp').textContent = (DATA.profiles[STATE.profile || ''] || {}).description || '';
        sel.onchange = () => { STATE.profile = sel.value; $('profileHelp').textContent = (DATA.profiles[STATE.profile] || {}).description || ''; compose(); };
      }

      function capsuleRow(c, id) {
        const item = document.createElement('div'); item.className = 'item'; item.dataset.id = id;
        const row = document.createElement('div'); row.className = 'row'; item.appendChild(row);

        const cb = document.createElement('input'); cb.type = 'checkbox'; cb.checked = STATE.selectedCaps.has(id);
        cb.addEventListener('change', () => {
          if (cb.checked) { STATE.selectedCaps.add(id); STATE.manualCaps.add(id); if (!STATE.order.includes(id)) STATE.order.push(id); }
          else { STATE.selectedCaps.delete(id); STATE.manualCaps.delete(id); STATE.order = STATE.order.filter(x => x !== id); }
          renderPreview(); compose();
        });
        row.appendChild(cb);

        const ttl = document.createElement('div'); ttl.textContent = (c.title || id) + '  -  ' + (c.domain || ''); row.appendChild(ttl);
        row.appendChild(badgeAuthor(c)); row.appendChild(badgeDigest(c));

        const btn = document.createElement('button'); btn.className = 'btn small'; btn.textContent = 'View'; btn.onclick = () => openModal(c.title || id, c);
        row.appendChild(btn);

        const small = document.createElement('div'); small.className = 'small'; small.textContent = (c.statement || ''); item.appendChild(small);
        return item;
      }

      function renderCapsules() {
        const list = $('capsules'); list.innerHTML = '';
        const f = (STATE.filter || '').toLowerCase();
        const ids = Object.keys(DATA.capsules || {}).filter(id => {
          const c = DATA.capsules[id] || {}; const hay = (id + ' ' + (c.title || '') + ' ' + (c.domain || '') + ' ' + (c.statement || '')).toLowerCase();
          return hay.includes(f);
        }).sort();
        ids.forEach(id => list.appendChild(capsuleRow(DATA.capsules[id], id)));
        $('capsulesCount').textContent = ids.length;
      }

      function renderBundles() {
        const list = $('bundles'); list.innerHTML = '';
        const keys = Object.keys(DATA.bundles || {}).sort((a, b) => (DATA.bundles[a].name || a).localeCompare(DATA.bundles[b].name || b));
        for (const k of keys) {
          const b = DATA.bundles[k] || {};
          const item = document.createElement('div'); item.className = 'item';
          const row = document.createElement('div'); row.className = 'row'; item.appendChild(row);

          const cb = document.createElement('input'); cb.type = 'checkbox'; cb.checked = STATE.selectedBundles.has(k);
          cb.addEventListener('change', () => {
            if (cb.checked) {
              STATE.selectedBundles.add(k);
              (b.capsules || []).forEach(cid => { STATE.selectedCaps.add(cid); if (!STATE.order.includes(cid)) STATE.order.push(cid); });
            } else {
              STATE.selectedBundles.delete(k);
              const others = [...STATE.selectedBundles];
              (b.capsules || []).forEach(cid => {
                const elsewhere = others.some(name => { const b2 = DATA.bundles[name]; return b2 && Array.isArray(b2.capsules) && b2.capsules.includes(cid); });
                const manual = STATE.manualCaps.has(cid);
                if (!elsewhere && !manual) STATE.selectedCaps.delete(cid);
                STATE.order = STATE.order.filter(x => STATE.selectedCaps.has(x));
              });
            }
            renderCapsules(); renderPreview(); compose();
          });
          row.appendChild(cb);

          const ttl = document.createElement('div'); ttl.textContent = (b.name || k); row.appendChild(ttl);

          // Add description if present
          if (b.description) {
            const desc = document.createElement('div'); desc.className = 'small'; desc.textContent = b.description; item.appendChild(desc);
          }

          list.appendChild(item);
        }
        $('bundlesCount').textContent = keys.length;
      }

      function renderPreview() {
        const list = $('preview'); list.innerHTML = '';
        const ids = STATE.order.filter(id => STATE.selectedCaps.has(id));
        ids.forEach(id => {
          const c = DATA.capsules[id]; if (!c) return;
          const item = document.createElement('div'); item.className = 'item'; item.dataset.id = id;

          const row = document.createElement('div'); row.className = 'row'; item.appendChild(row);
          const handle = document.createElement('span'); handle.className = 'chip drag'; handle.textContent = '‚ò∞'; row.appendChild(handle);
          const ttl = document.createElement('div'); ttl.textContent = (c.title || id) + '  -  ' + (c.domain || ''); row.appendChild(ttl);
          const btn = document.createElement('button'); btn.className = 'btn small'; btn.textContent = 'View'; btn.onclick = () => openModal(c.title || id, c); row.appendChild(btn);

          list.appendChild(item);
        });

        // Sortable (drag to reorder)
        if (window.__sortable) window.__sortable.destroy();
        window.__sortable = new Sortable(list, {
          animation: 120,
          handle: '.drag',
          ghostClass: 'ghost',
          onEnd: (evt) => {
            const old = STATE.order.filter(id => STATE.selectedCaps.has(id));
            const moved = old.splice(evt.oldIndex, 1)[0];
            old.splice(evt.newIndex, 0, moved);
            STATE.order = old.concat(STATE.order.filter(x => !STATE.selectedCaps.has(x)));
            compose();
          }
        });
      }

      /* ------------ Composition ------------ */
      function parseFieldSpec(spec) { const m = spec.match(/^([a-z_.]+)(?:\[:(\d+)\])?$/); return { path: m ? m[1] : spec, limit: m && m[2] ? parseInt(m[2]) : null }; }
      function applyProjection(capsule, projection, includePedagogy) {
        const proj = projection || {}; const include = proj.include || []; const render = proj.render || {};
        const header = render.capsule_header || "BEGIN CAPSULE id={id} version={version} domain={domain}";
        const footer = render.enforcement_footer || "ENFORCEMENT: Ensure outputs satisfy this capsule; otherwise abstain and request the minimal missing info.";
        const aBullet = render.assumption_bullet || "  - {text}";
        const sBullet = render.socratic_bullet || "  - {text}";
        const aphBullet = render.aphorism_bullet || "  - {text}";
        const lines = [];

        lines.push(header.replace('{id}', capsule.id || '').replace('{version}', capsule.version || '1.0.0').replace('{domain}', capsule.domain || ''));

        for (const spec of include) {
          const { path, limit } = parseFieldSpec(spec);
          if (path === 'title') { if (capsule.title) lines.push("TITLE: " + capsule.title); }
          else if (path === 'statement') { if (capsule.statement) lines.push("STATEMENT: " + capsule.statement); }
          else if (path === 'assumptions') {
            const items = (capsule.assumptions || []).slice(0, limit || Number.MAX_SAFE_INTEGER);
            if (items.length) { lines.push("ASSUMPTIONS:"); items.forEach(a => lines.push(aBullet.replace('{text}', a))); }
          }
          else if (path === 'pedagogy.socratic' && includePedagogy) {
            const soc = (capsule.pedagogy || []).filter(p => (p.kind || '').toLowerCase() === 'socratic').slice(0, limit || Number.MAX_SAFE_INTEGER);
            if (soc.length) { lines.push("PEDAGOGY (Socratic):"); soc.forEach(p => lines.push(sBullet.replace('{text}', p.text || ''))); }
          }
          else if (path === 'pedagogy.aphorisms' && includePedagogy) {
            const aph = (capsule.pedagogy || []).filter(p => (p.kind || '').toLowerCase() === 'aphorism').slice(0, limit || Number.MAX_SAFE_INTEGER);
            if (aph.length) { lines.push("PEDAGOGY (Aphorisms):"); aph.forEach(p => lines.push(aphBullet.replace('{text}', p.text || ''))); }
          }
        }

        lines.push(footer);
        return lines.join("\n");
      }
      function composeLegacy(c, includePedagogy) {
        const lines = [];
        lines.push("BEGIN CAPSULE id=" + (c.id || '') + " version=" + (c.version || '1.0.0') + " domain=" + (c.domain || ''));
        if (c.statement) lines.push("STATEMENT: " + c.statement);
        if (includePedagogy && c.pedagogy) {
          const ped = c.pedagogy.map(p => (p.kind + ': ' + p.text)).join('\n');
          if (ped) lines.push('PEDAGOGY:\n' + ped);
        }
        lines.push('END CAPSULE');
        return lines.join("\n");
      }
      function compose() {
        const prof = DATA.profiles[STATE.profile || ''] || {};
        const response = prof.response || {};
        const ids = STATE.order.filter(id => STATE.selectedCaps.has(id));
        const blocks = [];

        const policy = response.policy || 'Cite or abstain; follow Plan-Verify-Answer; ask ONE crisp follow-up if required.';
        const format = response.format || 'natural';
        const system_block = response.system_block || ("SYSTEM: Profile=" + (prof.title || 'unknown') + "\nPOLICY: " + policy + "\nFORMAT: " + format);
        blocks.push(system_block);

        blocks.push("SYSTEM: Truth Capsules Loader v1\nPURPOSE: Use curated capsules to scaffold reasoning and enforce acceptance rules.\nMETHOD:\n  1) Load capsule rules (below).\n  2) For each task, follow Plan ‚Üí Verify ‚Üí Answer.\n  3) If required fields are missing, ask ONE concise follow-up.\n  4) Cite sources or abstain. Redact PII. Validate tool JSON before calling.\n  5) Emit a JSON report when asked (see REPORT SCHEMA).\nFAILURE POLICY: If a capsule cannot be satisfied, abstain + explain what is missing.");
        blocks.push("SYSTEM: Bootstrap Discipline\n‚Ä¢ Curation is king - prefer curated fixtures/evidence; abstain when unsure.\n‚Ä¢ Show your work - reference evidence in answers.\n‚Ä¢ Make failures explicit and reversible - choose tiny experiments.");

        if (ids.length === 0) {
          blocks.push('SYSTEM: Capsule Rules (Selected)\n- (No capsules selected)');
        } else {
          blocks.push('SYSTEM: Capsule Rules (Selected)');
          const projection = response.projection || null;
          const withPed = $('includePed').checked;
          for (const id of ids) {
            const c = DATA.capsules[id]; if (!c) continue;
            blocks.push((projection && projection.include) ? applyProjection(c, projection, withPed) : composeLegacy(c, withPed));
          }
        }

        let out = blocks.join("\n\n");
        if ($('markdown').checked) out = "```\n" + out + "\n```";
        $('out').value = out;
      }

      /* ------------ Manifest + share ------------ */
      function buildManifest() { return { profile: STATE.profile, order: STATE.order.filter(id => STATE.selectedCaps.has(id)), bundles: [...STATE.selectedBundles], ts: new Date().toISOString() }; }
      function exportState() { return { profile: STATE.profile, bundles: [...STATE.selectedBundles], order: STATE.order.filter(id => STATE.selectedCaps.has(id)) }; }
      function encodeStateToUrl() {
        const s = btoa(unescape(encodeURIComponent(JSON.stringify(exportState()))));
        const url = new URL(window.location.href); url.searchParams.set('s', s); return url.toString();
      }
      function importState(obj) {
        if (!obj) return;
        const prof = obj.profile && DATA.profiles[obj.profile] ? obj.profile : (Object.keys(DATA.profiles || {})[0] || null);
        STATE.profile = prof; STATE.selectedBundles = new Set(); STATE.selectedCaps = new Set(); STATE.manualCaps = new Set(); STATE.order = [];
        (obj.bundles || []).forEach(b => { if (DATA.bundles[b]) STATE.selectedBundles.add(b); });
        STATE.selectedBundles.forEach(b => {
          const caps = (DATA.bundles[b] && DATA.bundles[b].capsules) || [];
          caps.forEach(cid => { if (DATA.capsules[cid]) { STATE.selectedCaps.add(cid); if (!STATE.order.includes(cid)) STATE.order.push(cid); } });
        });
        (obj.order || []).forEach(cid => { if (DATA.capsules[cid]) { if (!STATE.order.includes(cid)) STATE.order.push(cid); STATE.selectedCaps.add(cid); } });
        render();
      }
      function tryHydrateFromUrl() {
        const url = new URL(window.location.href); const s = url.searchParams.get('s'); if (!s) return;
        try { const json = decodeURIComponent(escape(atob(s))); importState(JSON.parse(json)); } catch (e) { console.error('bad s param', e); }
      }

      /* ------------ LLM Command Composition ------------ */
      function shQuoteLiteral(s) {
        // POSIX-safe single-quote wrapper: ' becomes '\''
        return "'" + String(s).replace(/'/g, "'\\''") + "'";
      }

      function buildSysHeredoc(promptText) {
        // Use single-quoted heredoc label to disable interpolation/globbing
        // Use TC_SYSTEM to avoid conflicts with user's shell variables
        const label = "__TC_SYSTEM__";
        return [
          `read -r -d '' TC_SYSTEM <<'${label}'`,
          promptText,
          label
        ].join("\n");
      }

      function buildInputFragment(tpl, userText, filePath) {
        const flags = (tpl.extra_flags || []).join(' ');

        if (tpl.input_mode === 'arg') {
          return {
            EXTRA_FLAGS: flags,
            INPUT_FRAGMENT: `<<< ${shQuoteLiteral(userText || "")}`
          };
        }

        if (tpl.input_mode === 'stdin') {
          return {
            EXTRA_FLAGS: flags,
            STDIN_PIPE: `printf %s ${shQuoteLiteral(userText || "")} |`,
            INPUT_FRAGMENT: ""
          };
        }

        if (tpl.input_mode === 'file') {
          return {
            EXTRA_FLAGS: flags,
            FILE_PATH: shQuoteLiteral(filePath || "input.txt"),
            INPUT_FRAGMENT: ""
          };
        }

        return { EXTRA_FLAGS: flags, INPUT_FRAGMENT: "" };
      }

      function composeLlmCommand(tpl, systemPrompt, userText, filePath, minify) {
        const sysText = minify ? systemPrompt.replace(/\s+/g, ' ').trim() : systemPrompt;
        const sysHeredoc = buildSysHeredoc(sysText);
        const frags = buildInputFragment(tpl, userText, filePath);

        // Build the command by replacing all placeholders
        let cmd = String(tpl.cmd_template || '');

        // Replace required placeholders
        cmd = cmd.replace(/\{\{SYS_HEREDOC\}\}/g, sysHeredoc);
        cmd = cmd.replace(/\{\{MODEL\}\}/g, tpl.model || '');
        cmd = cmd.replace(/\{\{INPUT_FRAGMENT\}\}/g, frags.INPUT_FRAGMENT || '');

        // Replace optional placeholders
        cmd = cmd.replace(/\{\{EXTRA_FLAGS\}\}/g, frags.EXTRA_FLAGS || '');
        cmd = cmd.replace(/\{\{STDIN_PIPE\}\}/g, frags.STDIN_PIPE || '');
        cmd = cmd.replace(/\{\{FILE_PATH\}\}/g, frags.FILE_PATH || '');

        // Clean up:
        // 1. Collapse multiple spaces into single space
        cmd = cmd.replace(/ {2,}/g, ' ');
        // 2. Remove trailing spaces on lines
        cmd = cmd.replace(/[ \t]+$/gm, '');
        // 3. Ensure final newline
        cmd = cmd.trim() + "\n";

        return cmd;
      }

      function getCurrentSystemPrompt() {
        // Get the current composed prompt, stripping markdown fences if present
        let prompt = $('out').value;
        if ($('markdown').checked) {
          // Remove leading ``` and trailing ```
          prompt = prompt.replace(/^```\n/, '').replace(/\n```$/, '');
        }
        return prompt;
      }

      function updateLlmPreview() {
        const templates = DATA.llm_templates || [];
        const selectedId = $('llm_template').value;
        const tpl = templates.find(t => t.id === selectedId);

        if (!tpl) {
          $('llm_preview').value = '';
          return;
        }

        const systemPrompt = getCurrentSystemPrompt();
        const userText = $('llm_user_input').value;
        const filePath = $('llm_file_path').value;
        const minify = $('llm_minify').checked;

        const command = composeLlmCommand(tpl, systemPrompt, userText, filePath, minify);
        $('llm_preview').value = command;
      }

      function openLlmModal() {
        const templates = DATA.llm_templates || [];

        if (templates.length === 0) {
          toast('No LLM templates found');
          return;
        }

        // Populate template selector
        const sel = $('llm_template');
        sel.innerHTML = '';
        templates.forEach(tpl => {
          const opt = document.createElement('option');
          opt.value = tpl.id;
          opt.textContent = tpl.label;
          sel.appendChild(opt);
        });

        // Restore last used template from localStorage
        const lastTemplate = localStorage.getItem('llm_last_template');
        if (lastTemplate && templates.find(t => t.id === lastTemplate)) {
          sel.value = lastTemplate;
        }

        // Update description and input mode on template change
        const updateTemplateUI = () => {
          const selectedId = sel.value;
          const tpl = templates.find(t => t.id === selectedId);
          if (!tpl) return;

          $('llm_template_desc').textContent = tpl.description || '';

          // Show/hide input fields based on input_mode
          if (tpl.input_mode === 'file') {
            $('llm_input_row').style.display = 'none';
            $('llm_file_row').style.display = 'flex';
          } else {
            $('llm_input_row').style.display = 'flex';
            $('llm_file_row').style.display = 'none';

            if (tpl.input_mode === 'stdin') {
              $('llm_input_hint').textContent = 'Will be piped to stdin';
            } else {
              $('llm_input_hint').textContent = 'Will be passed as bash here-string (<<<)';
            }
          }

          // Update preview whenever template changes
          updateLlmPreview();
        };

        sel.onchange = updateTemplateUI;

        // Update preview on input changes
        $('llm_user_input').oninput = updateLlmPreview;
        $('llm_file_path').oninput = updateLlmPreview;
        $('llm_minify').onchange = updateLlmPreview;

        updateTemplateUI();

        // Clear inputs (but preserve file path default)
        $('llm_user_input').value = '';
        $('llm_file_path').value = 'input.txt';
        $('llm_minify').checked = false;

        // Initial preview
        updateLlmPreview();

        $('llmModal').style.display = 'flex';
      }

      function closeLlmModal() {
        $('llmModal').style.display = 'none';
      }

      function copyLlmCommand() {
        const command = $('llm_preview').value;

        if (!command) {
          toast('No command to copy');
          return;
        }

        // Save the selected template to localStorage
        const selectedId = $('llm_template').value;
        if (selectedId) {
          localStorage.setItem('llm_last_template', selectedId);
        }

        navigator.clipboard.writeText(command).then(() => {
          toast('Command copied to clipboard!');
          // Don't close the modal - let user copy again or review
        }).catch(err => {
          console.error('Copy failed:', err);
          toast('Copy failed - see console');
        });
      }

      // Save the generated command as a runnable bash script
      function saveLlmScript() {
        const command = $('llm_preview').value;
        if (!command) {
          toast('No command to save');
          return;
        }

        const tplId = $('llm_template').value || 'cmd';
        const nowIso = new Date().toISOString();
        const filename = `llm_${tplId}_${nowIso.replace(/[:.]/g, '-')}.sh`;

        const header =
          `#!/usr/bin/env bash
# Generated by Truth Capsule Composer
# Template: ${tplId}
# Date: ${nowIso}
set -Eeuo pipefail
IFS=$'\\n\\t'

`;

        const blob = new Blob([header, command], { type: 'text/x-shellscript' });
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = filename;
        document.body.appendChild(a);
        a.click();
        setTimeout(() => URL.revokeObjectURL(a.href), 1000);
        a.remove();
        toast(`Saved ${filename} (remember: chmod +x ${filename})`);
      }
      function copyLlmCommand() {
        const command = $('llm_preview').value;

        if (!command) {
          toast('No command to copy');
          return;
        }

        // Save the selected template to localStorage
        const selectedId = $('llm_template').value;
        if (selectedId) {
          localStorage.setItem('llm_last_template', selectedId);
        }

        navigator.clipboard.writeText(command).then(() => {
          toast('Command copied to clipboard!');
          // Don't close the modal - let user copy again or review
        }).catch(err => {
          console.error('Copy failed:', err);
          toast('Copy failed - see console');
        });
      }

      // Wire up LLM modal events
      $('copyLlmBtn').addEventListener('click', openLlmModal);
      $('llm_close').addEventListener('click', closeLlmModal);
      $('llm_cancel').addEventListener('click', closeLlmModal);
      $('llm_copy').addEventListener('click', copyLlmCommand);
      $('llm_save').addEventListener('click', saveLlmScript)
      $('llmModal').addEventListener('click', e => {
        if (e.target && e.target.id === 'llmModal') closeLlmModal();
      });

      /* ------------ Wire up UI ------------ */
      $('search').addEventListener('input', () => { STATE.filter = $('search').value; renderCapsules(); });
      $('clearBtn').addEventListener('click', () => { STATE.selectedBundles = new Set(); STATE.selectedCaps = new Set(); STATE.manualCaps = new Set(); STATE.order = []; render(); toast('Cleared'); });
      $('composeBtn').addEventListener('click', compose);
      $('copyBtn').addEventListener('click', () => { navigator.clipboard.writeText($('out').value); toast('Prompt copied'); });
      $('dlBtn').addEventListener('click', () => { const blob = new Blob([$('out').value], { type: 'text/plain' }); const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = 'system_prompt.txt'; a.click(); });
      $('dlJsonBtn').addEventListener('click', () => { const a = document.createElement('a'); a.href = URL.createObjectURL(new Blob([JSON.stringify(buildManifest(), null, 2)], { type: 'application/json' })); a.download = 'system_prompt.manifest.json'; a.click(); });
      $('shareLinkBtn').addEventListener('click', () => { const url = encodeStateToUrl(); navigator.clipboard.writeText(url).then(() => toast('Share link copied')).catch(() => { prompt('Copy link:', url); }); });
      $('loadJsonBtn').addEventListener('click', () => { const inp = document.createElement('input'); inp.type = 'file'; inp.accept = 'application/json'; inp.onchange = async () => { const f = inp.files[0]; if (!f) return; const txt = await f.text(); importState(JSON.parse(txt)); toast('State loaded'); }; inp.click(); });
      $('validateAllBtn').addEventListener('click', async () => {
        const ids = STATE.order.filter(id => STATE.selectedCaps.has(id)); const results = [];
        for (const id of ids) { const c = DATA.capsules[id]; if (!c) continue; const v = await validateDigest(c); results.push({ id, ok: v.ok }); }
        const ok = results.filter(r => r.ok).length; const fail = results.length - ok;
        toast(`Digests: ${ok} ok, ${fail} fail`); try { await navigator.clipboard.writeText(results.map(r => (r.ok ? '‚úì ' : '‚úó ') + r.id).join('\n')); } catch { }
      });
      $('includePed').addEventListener('change', compose);
      $('markdown').addEventListener('change', compose);

      /* Keyboard shortcuts */
      document.addEventListener('keydown', (e) => {
        if ((e.metaKey || e.ctrlKey) && e.key === 'Enter') { compose(); }
        if (e.key === '/') { e.preventDefault(); $('search').focus(); }
        if (e.key === 'm') { $('markdown').checked = !$('markdown').checked; compose(); }
        if (e.key === 'p') { $('includePed').checked = !$('includePed').checked; compose(); }
      });

      function render() { renderProfiles(); renderBundles(); renderCapsules(); renderPreview(); compose(); }
      render();
      tryHydrateFromUrl();

      // Remember splits
      const mainSizes = JSON.parse(localStorage.getItem('tc_split_main') || '[30,70]');
      Split(['#left', '#right'], { sizes: mainSizes, minSize: 240, gutterSize: 8, onDragEnd: s => localStorage.setItem('tc_split_main', JSON.stringify(s)) });

      const subSizes = JSON.parse(localStorage.getItem('tc_split_sub') || '[45,55]');
      Split(['#bundlesWrap', '#capsulesWrap'], { direction: 'vertical', sizes: subSizes, minSize: [80, 120], gutterSize: 8, onDragEnd: s => localStorage.setItem('tc_split_sub', JSON.stringify(s)) });

      // Remember profile + checkboxes
      $('profiles').addEventListener('change', () => localStorage.setItem('tc_profile', $('profiles').value));
      $('includePed').addEventListener('change', () => localStorage.setItem('tc_inc_ped', $('includePed').checked ? '1' : '0'));
      $('markdown').addEventListener('change', () => localStorage.setItem('tc_md', $('markdown').checked ? '1' : '0'));

      window.addEventListener('load', () => {
        const p = localStorage.getItem('tc_profile'); if (p && DATA.profiles[p]) $('profiles').value = p;
        $('includePed').checked = localStorage.getItem('tc_inc_ped') !== '0';
        $('markdown').checked = localStorage.getItem('tc_md') === '1';
      });


    </script>
</body>

</html>